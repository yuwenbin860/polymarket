#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Polymarket ç»„åˆå¥—åˆ©ç³»ç»Ÿ - æœ¬åœ°å®Œæ•´ç‰ˆ v2
========================================

æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œå¯å¿«é€Ÿåˆ‡æ¢ï¼š
- SiliconFlow (å›½å†…èšåˆï¼Œæ¨è)
- DeepSeek (ä¾¿å®œå¥½ç”¨)
- OpenAI / Anthropic / é˜¿é‡Œäº‘ / æ™ºè°±
- Ollama (æœ¬åœ°å…è´¹)

ä½¿ç”¨æ–¹æ³•ï¼š
    # æ–¹å¼1: ä½¿ç”¨é¢„è®¾é…ç½®ï¼ˆæ¨èï¼‰
    python local_scanner_v2.py --profile siliconflow
    python local_scanner_v2.py --profile deepseek
    python local_scanner_v2.py --profile ollama
    
    # æ–¹å¼2: ç¯å¢ƒå˜é‡
    export SILICONFLOW_API_KEY="your-key"
    python local_scanner_v2.py --profile siliconflow
    
    # æ–¹å¼3: è‡ªåŠ¨æ£€æµ‹
    python local_scanner_v2.py
    
    # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨é…ç½®
    python llm_config.py --list
    
    # åˆ‡æ¢æ¨¡å‹
    python local_scanner_v2.py --profile siliconflow --model deepseek-ai/DeepSeek-V3
"""

import logging
import traceback
import requests
import json
import os
import sys
import sqlite3
import argparse
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field, asdict, is_dataclass
from pathlib import Path
from typing import List, Optional, Dict, Tuple, Any
from collections import defaultdict
from enum import Enum

# ============================================================
# UTF-8ç¼–ç é…ç½® - å·²é€šè¿‡emojiâ†’ASCIIæ›¿æ¢è§£å†³ç¼–ç é—®é¢˜
# ============================================================
# æ³¨æ„ï¼šç”±äºio.TextIOWrapperä¼šå¯¼è‡´stderrå…³é—­é—®é¢˜ï¼Œ
# æˆ‘ä»¬é‡‡ç”¨æ›´ç®€å•çš„æ–¹æ¡ˆï¼šæ‰€æœ‰emojiå·²æ›¿æ¢ä¸ºASCIIå­—ç¬¦
from datetime import datetime, UTC, timezone, timedelta
from enum import Enum

# å¯¼å…¥LLMæä¾›å•†å’Œé…ç½®
from llm_providers import create_llm_client, BaseLLMClient, LLMResponse
from config import Config as AppConfig
from prompts import (
    format_analysis_prompt,
    format_exhaustive_prompt,
    PromptConfig,
    RELATIONSHIP_ANALYSIS_PROMPT_V2
)

# âœ… æ–°å¢ï¼šå¯¼å…¥éªŒè¯å±‚
from validators import MathValidator

# âœ… æ–°å¢ï¼šå¯¼å…¥åŠ¨æ€åˆ†ç±»æ¨¡å— (v3.1)
from category_discovery import CategoryDiscovery, CategoryInfo

# âœ… æ–°å¢ï¼šå¯¼å…¥éªŒè¯å¼•æ“ (v2.5)
from validation_engine import ValidationEngine
from notifier import ArbitrageNotifier
from execution_engine import ExecutionEngine
from semantic_cluster import SemanticClusterer
from data_recorder import TimeSeriesRecorder
from backtest_engine import BacktestEngine
from secret_manager import secrets
from ws_client import PolymarketWSClient

# âœ… æ–°å¢ï¼šå¯¼å…¥ CLI æ¨¡å—ï¼ˆv3.1ï¼‰
try:
    from cli import InteractiveMenu, ScannerOutput
    from strategies import StrategyRegistry, BaseArbitrageStrategy, StrategyMetadata
    CLI_AVAILABLE = True
except ImportError:
    CLI_AVAILABLE = False
    InteractiveMenu = None
    ScannerOutput = None
    StrategyRegistry = None

# ============================================================
# Logging é…ç½®
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ============================================================
# ğŸ†• å­ç±»åˆ«ç®€å†™æ˜ å°„ï¼ˆv2.1æ–°å¢ï¼‰
# ============================================================
# æ”¯æŒå¸¸è§å¸ç§/æ ‡ç­¾çš„ç®€å†™ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿè¾“å…¥
SUBCATEGORY_ALIASES = {
    "btc": "bitcoin",
    "eth": "ethereum",
    "sol": "solana",
    "bnb": "bnb",
    "xrp": "xrp",
    "ada": "cardano",  # adaå¯¹åº”cardano
    "dot": "polkadot",
    "avax": "avalanche",
    "matic": "polygon",
    "uni": "uniswap",
    "aave": "aave",
    "comp": "compound",
    "link": "chainlink",
}


# ============================================================
# æ•°æ®ç»“æ„
# ============================================================


class RelationType(Enum):
    IMPLIES_AB = "implies_ab"
    IMPLIES_BA = "implies_ba"
    EQUIVALENT = "equivalent"
    MUTUAL_EXCLUSIVE = "mutual_exclusive"
    EXHAUSTIVE = "exhaustive"
    UNRELATED = "unrelated"

    # âœ… æ–°å¢: åŒºé—´å…³ç³»ç±»å‹
    INTERVAL_COVERS = "interval_covers"      # Açš„åŒºé—´è¦†ç›–Bï¼ˆBæ˜¯Açš„å­é›†ï¼‰
    INTERVAL_SUBSET = "interval_subset"      # Aæ˜¯Bçš„å­é›†
    INTERVAL_OVERLAP = "interval_overlap"    # åŒºé—´é‡å 


class RunMode(Enum):
    """è¿è¡Œæ¨¡å¼æšä¸¾"""
    DEBUG = "debug"           # è°ƒè¯•æ¨¡å¼ï¼šå‘ç°å¥—åˆ©åæš‚åœç¡®è®¤
    PRODUCTION = "production" # ç”Ÿäº§æ¨¡å¼ï¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰æœºä¼šï¼Œæ— äººå€¼å®ˆè¿è¡Œ


@dataclass
class Market:
    id: str
    condition_id: str
    question: str
    description: str              # Market-level description (legacy, may be empty)
    yes_price: float              # ä¸­é—´ä»·/å‚è€ƒä»· (å±•ç¤ºç”¨)
    no_price: float               # 1 - yes_price (å±•ç¤ºç”¨)
    volume: float
    liquidity: float
    end_date: str
    event_id: str
    event_title: str
    resolution_source: str
    outcomes: List[str]
    # é™·é˜±1ä¿®å¤: å¢åŠ çœŸå®çš„ Bid/Ask ä»·æ ¼
    best_bid: float = 0.0         # æœ€ä½³ä¹°ä»· (ä½ å–å‡ºæ—¶çš„ä»·æ ¼)
    best_ask: float = 0.0         # æœ€ä½³å–ä»· (ä½ ä¹°å…¥æ—¶çš„ä»·æ ¼)
    spread: float = 0.0           # ä»·å·® = ask - bid
    token_id: str = ""            # CLOB token ID - YES token (ç”¨äºè·å–è®¢å•ç°¿)
    # å•è°ƒæ€§å¥—åˆ©ä¿®å¤: å¢åŠ  NO token ç›¸å…³å­—æ®µ
    no_token_id: str = ""         # CLOB token ID - NO token
    best_bid_no: float = 0.0      # NOçš„æœ€ä½³ä¹°ä»·
    best_ask_no: float = 0.0      # NOçš„æœ€ä½³å–ä»·

    # âœ… æ–°å¢: Rulesåˆ†æç›¸å…³å­—æ®µ
    event_description: str = ""   # Eventçš„description (åŒ…å«resolution rules!)
    market_description: str = ""  # Marketè‡ªå·±çš„description
    tags: List[Dict] = None       # Eventçš„tags (ç”¨äºåˆ†ç±»è¿‡æ»¤)
    orderbook: Dict = None        # Full orderbook data (for arbitrage opportunity reporting)

    # âœ… æ–°å¢: åŒºé—´å¸‚åœºç›¸å…³å­—æ®µ (ç”¨äºå¤šoutcome/åŒºé—´å¸‚åœºå¥—åˆ©)
    group_item_title: str = ""     # åŒºé—´æ˜¾ç¤ºåç§° (å¦‚ "80,000-82,000")
    group_item_threshold: str = "" # åŒºé—´æ’åºåºå· (å¦‚ "0", "1", "2"...)
    interval_type: str = ""        # åŒºé—´ç±»å‹: "below", "range", "above", ""
    interval_lower: float = None   # åŒºé—´ä¸‹ç•Œ (å¦‚ 80000)
    interval_upper: float = None   # åŒºé—´ä¸Šç•Œ (å¦‚ 82000)


    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.orderbook is None:
            self.orderbook = {}
    def __repr__(self):
        return f"Market('{self.question[:50]}...', YES=${self.yes_price:.2f}, spread={self.spread:.3f})"

    @property
    def full_description(self) -> str:
        """è·å–å®Œæ•´çš„æè¿°ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨event_descriptionï¼‰"""
        if self.event_description:
            return self.event_description
        return self.market_description or self.description

    @property
    def effective_buy_price(self) -> float:
        """å®é™…ä¹°å…¥ä»·æ ¼ - å¥—åˆ©è®¡ç®—æ—¶ä½¿ç”¨ best_ask"""
        return self.best_ask if self.best_ask > 0 else self.yes_price

    @property
    def effective_sell_price(self) -> float:
        """å®é™…å–å‡ºä»·æ ¼ - å¥—åˆ©è®¡ç®—æ—¶ä½¿ç”¨ best_bid"""
        return self.best_bid if self.best_bid > 0 else self.yes_price

    @property
    def is_expired(self) -> bool:
        """æ£€æŸ¥å¸‚åœºæ˜¯å¦å·²è¿‡æœŸï¼ˆend_dateå·²è¿‡ï¼‰

        Note: Polymarket API dates are in UTC, so we use UTC time for comparison
        """
        if not self.end_date:
            return False  # æ— ç»“ç®—æ—¥æœŸçš„å¸‚åœºè§†ä¸ºæœªè¿‡æœŸ
        try:
            # è§£æ end_dateï¼Œæ”¯æŒå¤šç§æ ¼å¼
            date_str = self.end_date
            if 'T' in date_str:
                # ISO 8601 æ ¼å¼: "2024-01-15T00:00:00Z" æˆ– "2024-01-15T00:00:00.000Z"
                date_str = date_str.split('T')[0]
            # è§£ææ—¥æœŸéƒ¨åˆ†
            end_dt = datetime.strptime(date_str, "%Y-%m-%d")
            # ä½¿ç”¨UTCæ—¶é—´æ¯”è¾ƒï¼Œå› ä¸ºPolymarket APIä½¿ç”¨UTC
            from datetime import timezone
            now_utc = datetime.now(timezone.utc)
            # å¦‚æœ end_date åœ¨UTCä»Šå¤©ä¹‹å‰ï¼Œåˆ™è§†ä¸ºå·²è¿‡æœŸ
            return end_dt.date() < now_utc.date()
        except (ValueError, TypeError):
            return False  # è§£æå¤±è´¥åˆ™è§†ä¸ºæœªè¿‡æœŸï¼Œä¿å®ˆå¤„ç†


@dataclass
class ArbitrageOpportunity:
    id: str
    type: str
    markets: List[Dict]
    relationship: str
    confidence: float
    total_cost: float
    guaranteed_return: float
    profit: float
    profit_pct: float
    action: str
    reasoning: str
    edge_cases: List[str]
    needs_review: List[str]
    timestamp: str

    # ğŸ†• Phase 2.5 æ–°å¢é£æ§å­—æ®µ
    mid_price_profit: float = 0.0      # åŸºäºä¸­é—´ä»·çš„ç†è®ºåˆ©æ¶¦
    effective_profit: float = 0.0      # è€ƒè™‘è®¢å•ç°¿æ·±åº¦åçš„å®é™…åˆ©æ¶¦
    slippage_cost: float = 0.0         # é¢„ä¼°æ»‘ç‚¹æŸå¤± (USD)
    days_to_resolution: int = 0        # è·ç¦»ç»“ç®—çš„é¢„ä¼°å¤©æ•°
    apy: float = 0.0                   # å¹´åŒ–æ”¶ç›Šç‡ (%)
    apy_rating: str = "N/A"            # æ”¶ç›Šè¯„çº§ (EXCELLENT, GOOD, etc.)
    oracle_alignment: str = "UNKNOWN"  # é¢„è¨€æœºå¯¹é½çŠ¶æ€ (ALIGNED, MISALIGNED)
    validation_results: Dict = field(default_factory=dict)  # äº”å±‚éªŒè¯çš„è¯¦ç»†ç»“æœ
    checklist_path: str = ""           # è‡ªåŠ¨ç”Ÿæˆçš„ Markdown å¤æ ¸æ¸…å•è·¯å¾„
    gas_estimate: float = 0.0          # é¢„ä¼°æ‰§è¡Œæ‰€éœ€çš„ Gas è´¹ (USD)
    max_position_usd: float = 0.0      # å»ºè®®çš„æœ€å¤§æŠ•å…¥é‡‘é¢ (USD)


# ============================================================
# JSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°
# ============================================================

def json_serialize(obj: Any) -> Any:
    """
    é€’å½’åºåˆ—åŒ–å¯¹è±¡ä¸ºJSONå…¼å®¹æ ¼å¼

    å¤„ç†:
    - dataclasså¯¹è±¡ -> dict
    - Enumå¯¹è±¡ -> value
    - å…¶ä»–ä¸å¯åºåˆ—åŒ–å¯¹è±¡ -> str
    """
    if is_dataclass(obj):
        return {k: json_serialize(v) for k, v in asdict(obj).items()}
    elif isinstance(obj, Enum):
        return obj.value
    elif isinstance(obj, dict):
        return {k: json_serialize(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [json_serialize(item) for item in obj]
    else:
        return obj


# ============================================================
# é€Ÿç‡é™åˆ¶å™¨
# ============================================================

import threading

class RateLimiter:
    """ç®€å•çš„é€Ÿç‡é™åˆ¶å™¨ï¼Œæ§åˆ¶APIè¯·æ±‚é¢‘ç‡ (çº¿ç¨‹å®‰å…¨)"""

    def __init__(self, calls_per_second: float = 2.0):
        """
        åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨

        Args:
            calls_per_second: æ¯ç§’å…è®¸çš„è¯·æ±‚æ•°
        """
        self.min_interval = 1.0 / calls_per_second
        self.last_call = 0
        self.lock = threading.Lock()

    def wait(self):
        """åœ¨å‘èµ·è¯·æ±‚å‰è°ƒç”¨ï¼Œç¡®ä¿ä¸è¶…è¿‡é€Ÿç‡é™åˆ¶"""
        import time
        with self.lock:
            elapsed = time.time() - self.last_call
            if elapsed < self.min_interval:
                time.sleep(self.min_interval - elapsed)
            self.last_call = time.time()


# ============================================================
# Polymarket APIå®¢æˆ·ç«¯
# ============================================================

class PolymarketClient:
    """Polymarket APIå®¢æˆ·ç«¯"""

    def __init__(
        self,
        api_base: str = "https://gamma-api.polymarket.com",
        rate_limit: float = 2.0
    ):
        """
        åˆå§‹åŒ– Polymarket API å®¢æˆ·ç«¯

        Args:
            api_base: APIåŸºç¡€URL
            rate_limit: æ¯ç§’è¯·æ±‚æ•°é™åˆ¶ï¼ˆé»˜è®¤2æ¬¡/ç§’ï¼‰
        """
        self.base_url = api_base
        self.session = requests.Session()

        # ğŸ†• é…ç½®é‡è¯•ç­–ç•¥ (Phase 5.3 ç¨³å®šæ€§å¢å¼º)
        from requests.adapters import HTTPAdapter
        from urllib3.util import Retry
        retries = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            raise_on_status=False
        )
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

        self.session.headers.update({
            "User-Agent": "PolymarketArbitrageScanner/2.0"
        })
        # åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
        self.rate_limiter = RateLimiter(calls_per_second=rate_limit)
    
    def get_markets(self, limit: int = 100, active: bool = True, 
                    min_liquidity: float = 0) -> List[Market]:
        """è·å–å¸‚åœºåˆ—è¡¨"""
        url = f"{self.base_url}/markets"
        params = {
            "limit": limit,
            "active": str(active).lower(),
            "closed": "false",
            "order": "volume",
            "ascending": "false"
        }
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            markets = []
            for item in data:
                try:
                    market = self._parse_market(item)
                    # è¿‡æ»¤æ‰å·²è¿‡æœŸçš„å¸‚åœºå’ŒæµåŠ¨æ€§ä¸è¶³çš„å¸‚åœº
                    if market and market.liquidity >= min_liquidity and not market.is_expired:
                        markets.append(market)
                except Exception as e:
                    continue
            
            return markets
            
        except requests.RequestException as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def _parse_market(self, data: Dict, event_data: Dict = None) -> Optional[Market]:
        """
        è§£æå¸‚åœºæ•°æ®

        Args:
            data: Market APIè¿”å›çš„æ•°æ®
            event_data: Event APIè¿”å›çš„æ•°æ®ï¼ˆå¦‚æœä»eventsç«¯ç‚¹è·å–ï¼‰

        Returns:
            Marketå¯¹è±¡æˆ–None
        """
        try:
            outcome_prices = data.get('outcomePrices', '["0.5","0.5"]')
            if isinstance(outcome_prices, str):
                prices = json.loads(outcome_prices)
            else:
                prices = outcome_prices

            yes_price = float(prices[0]) if prices else 0.5

            outcomes_str = data.get('outcomes', '["Yes","No"]')
            if isinstance(outcomes_str, str):
                outcomes = json.loads(outcomes_str)
            else:
                outcomes = outcomes_str

            # é™·é˜±1ä¿®å¤: è·å– CLOB token ID (ç”¨äºåç»­è·å–è®¢å•ç°¿)
            clob_token_ids = data.get('clobTokenIds', '[]')
            if isinstance(clob_token_ids, str):
                try:
                    token_ids = json.loads(clob_token_ids)
                except:
                    token_ids = []
            else:
                token_ids = clob_token_ids or []
            # YES token æ˜¯ç¬¬ä¸€ä¸ª, NO token æ˜¯ç¬¬äºŒä¸ª
            yes_token_id = token_ids[0] if len(token_ids) > 0 else ""
            no_token_id = token_ids[1] if len(token_ids) > 1 else ""

            # âœ… æ–°å¢: æå–Eventçº§åˆ«çš„descriptionå’Œtags
            event_description = ""
            tags = []
            if event_data:
                event_description = event_data.get('description', '')
                tags = event_data.get('tags', [])

            # âœ… æ–°å¢: Marketè‡ªå·±çš„description
            market_description = data.get('description', '')

            # å…¼å®¹æ—§çš„descriptionå­—æ®µ
            description = market_description or event_description

            # âœ… æ–°å¢: è§£æåŒºé—´å¸‚åœºä¿¡æ¯
            group_item_title = data.get('groupItemTitle', '')
            group_item_threshold = data.get('groupItemThreshold', '')

            # ä½¿ç”¨åŒºé—´è§£æå™¨è§£æåŒºé—´ä¿¡æ¯
            interval_type = ""
            interval_lower = None
            interval_upper = None

            question = data.get('question', '')

            if group_item_title or question:
                from interval_parser_v2 import IntervalParser
                parser = IntervalParser()

                # ä¼˜å…ˆä» groupItemTitle è§£æï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» question è§£æ
                interval = parser.parse(group_item_title, question)
                if interval:
                    interval_type = interval.type.value
                    interval_lower = interval.lower
                    interval_upper = interval.upper if interval.upper != float('inf') else None

            # /events API è¿”å›çš„marketæ•°æ®æ²¡æœ‰liquidityå­—æ®µï¼Œä½¿ç”¨volumeä½œä¸ºæµåŠ¨æ€§æŒ‡æ ‡
            liquidity_value = data.get('liquidity')
            if liquidity_value is None:
                liquidity_value = data.get('volume', 0)

            market = Market(
                id=data.get('id', ''),
                condition_id=data.get('conditionId', ''),
                question=question,
                description=description,
                yes_price=yes_price,
                no_price=1 - yes_price,
                volume=float(data.get('volume', 0) or 0),
                liquidity=float(liquidity_value or 0),
                end_date=data.get('endDate', ''),
                event_id=(event_data.get('slug', '') if event_data else '') or data.get('eventSlug', '') or '',
                event_title=(event_data.get('title', '') if event_data else '') or data.get('groupItemTitle', '') or '',
                resolution_source=data.get('resolutionSource', ''),
                outcomes=outcomes,
                token_id=yes_token_id,
                no_token_id=no_token_id,
                event_description=event_description,
                market_description=market_description,
                tags=tags,
                # âœ… æ–°å¢: åŒºé—´å¸‚åœºå­—æ®µ
                group_item_title=group_item_title,
                group_item_threshold=group_item_threshold,
                interval_type=interval_type,
                interval_lower=interval_lower,
                interval_upper=interval_upper
            )

            return market
        except Exception:
            return None

    def get_market_details(self, market_id: str) -> Optional[Dict]:
        """
        [Phase 4.8] è·å–å•ä¸ªå¸‚åœºçš„è¯¦ç»†æ•°æ® (ç”¨äºç»“ç®—æ£€æŸ¥)
        """
        if not market_id:
            return None

        # éµå®ˆé€Ÿç‡é™åˆ¶
        if hasattr(self, 'rate_limiter'):
            self.rate_limiter.wait()

        url = f"{self.base_url}/markets/{market_id}"
        try:
            response = self.session.get(url, timeout=15)
            if response.status_code == 404:
                return None
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logging.debug(f"è·å–å¸‚åœºè¯¦æƒ…å¤±è´¥ {market_id}: {e}")
            return None

    def fetch_orderbook(self, token_id: str) -> Dict:
        """
        ä» CLOB API è·å–è®¢å•ç°¿æ•°æ®

        é™·é˜±1ä¿®å¤: è·å–çœŸå®çš„ Bid/Ask ä»·æ ¼

        Args:
            token_id: CLOB token ID

        Returns:
            {"best_bid": float, "best_ask": float, "spread": float}
        """
        if not token_id:
            return {"best_bid": 0.0, "best_ask": 0.0, "spread": 0.0}

        # âœ… éµå®ˆé€Ÿç‡é™åˆ¶
        if hasattr(self, 'rate_limiter'):
            self.rate_limiter.wait()

        clob_url = f"https://clob.polymarket.com/book"
        try:
            response = self.session.get(
                clob_url,
                params={"token_id": token_id},
                timeout=10
            )
            response.raise_for_status()
            data = response.json()

            # è§£æè®¢å•ç°¿
            bids = data.get("bids", [])
            asks = data.get("asks", [])

            # Best bid = æœ€é«˜ä¹°ä»· (åˆ«äººæ„¿æ„ä¹°çš„æœ€é«˜ä»·)
            best_bid = float(bids[0]["price"]) if bids else 0.0
            # Best ask = æœ€ä½å–ä»· (åˆ«äººæ„¿æ„å–çš„æœ€ä½ä»·)
            best_ask = float(asks[0]["price"]) if asks else 0.0
            spread = best_ask - best_bid if (best_ask > 0 and best_bid > 0) else 0.0

            return {
                "best_bid": best_bid,
                "best_ask": best_ask,
                "spread": spread
            }
        except Exception as e:
            # é™é»˜å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            return {"best_bid": 0.0, "best_ask": 0.0, "spread": 0.0}

    def enrich_market_with_orderbook(self, market: Market) -> Market:
        """
        ä¸ºå¸‚åœºå¯¹è±¡è¡¥å……è®¢å•ç°¿æ•°æ®

        Args:
            market: Market å¯¹è±¡

        Returns:
            è¡¥å……äº† best_bid/best_ask/spread çš„ Market å¯¹è±¡
        """
        if not market.token_id:
            return market

        orderbook = self.fetch_orderbook(market.token_id)
        market.best_bid = orderbook["best_bid"]
        market.best_ask = orderbook["best_ask"]
        market.spread = orderbook["spread"]
        market.orderbook = orderbook  # Store full orderbook for arbitrage reporting

        return market

    def enrich_with_no_orderbook(self, market: Market) -> Market:
        """
        ä¸ºå¸‚åœºå¯¹è±¡è¡¥å…… NO token çš„è®¢å•ç°¿æ•°æ®

        å•è°ƒæ€§å¥—åˆ©ä¿®å¤: è·å–çœŸå®çš„ NO ä¹°å…¥ä»·ï¼Œè€Œéç”¨ 1 - YESä»·æ ¼ ä¼°ç®—

        Args:
            market: Market å¯¹è±¡

        Returns:
            è¡¥å……äº† best_bid_no/best_ask_no çš„ Market å¯¹è±¡
        """
        if not market.no_token_id:
            return market

        try:
            no_orderbook = self.fetch_orderbook(market.no_token_id)
            market.best_bid_no = no_orderbook["best_bid"]
            market.best_ask_no = no_orderbook["best_ask"]
        except Exception as e:
            logger.warning(f"è·å–NOè®¢å•ç°¿å¤±è´¥: {e}")

        return market

    def get_events_by_tag(
        self,
        tag_id: str,
        active: bool = True,
        limit: int = 100,
        max_results: int = None,
        page_size: int = 100
    ) -> List[Dict]:
        """
        æŒ‰tag_idè·å–eventsï¼ˆæ”¯æŒåˆ†é¡µï¼‰

        Args:
            tag_id: Tag ID (e.g., "21" for crypto)
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒäº‹ä»¶
            limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆæ—§è¡Œä¸ºå…¼å®¹ï¼Œå½“max_results=Noneæ—¶ä½¿ç”¨ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°ï¼ˆNone=æ—§è¡Œä¸ºç”¨limitï¼Œ0=å…¨é‡è·å–ï¼Œ>0=æŒ‡å®šæ•°é‡ï¼‰
            page_size: æ¯é¡µå¤§å°ï¼ˆé»˜è®¤100ï¼‰

        Returns:
            Eventå­—å…¸åˆ—è¡¨
        """
        # é»˜è®¤è¡Œä¸ºï¼šmax_results=None æ—¶ï¼Œä½¿ç”¨ limit ä½œä¸ºæœ€å¤§æ•°é‡
        if max_results is None:
            max_results = limit
        elif max_results == 0:
            # 0 è¡¨ç¤ºå…¨é‡è·å–ï¼Œè®¾ç½®ä¸€ä¸ªå¾ˆå¤§çš„æ•°
            max_results = float('inf')

        all_events = []
        offset = 0

        while True:
            # ç»ˆæ­¢æ¡ä»¶1: å·²è¾¾åˆ°æœ€å¤§ç»“æœæ•°
            if len(all_events) >= max_results:
                break

            # è®¡ç®—æœ¬æ¬¡è¯·æ±‚éœ€è¦è·å–çš„æ•°é‡
            current_limit = min(page_size, max_results - len(all_events))

            try:
                # é€Ÿç‡é™åˆ¶
                self.rate_limiter.wait()

                params = {
                    "tag_id": tag_id,
                    "limit": current_limit,
                    "offset": offset,
                    "closed": "false"  # åœ¨APIå±‚é¢è¿‡æ»¤å·²å…³é—­çš„äº‹ä»¶
                }
                if active is not None:
                    params["active"] = str(active).lower()

                url = f"{self.base_url}/events"
                response = self.session.get(url, params=params, timeout=10)
                response.raise_for_status()
                events = response.json()

                # ç»ˆæ­¢æ¡ä»¶2: è¿”å›ç©ºæ•°ç»„ï¼ˆæ²¡æœ‰æ›´å¤šæ•°æ®ï¼‰
                if not events:
                    break

                all_events.extend(events)

                # å…¨é‡è·å–æ¨¡å¼ï¼šè¾“å‡ºè¿›åº¦æ—¥å¿—
                if max_results == float('inf'):
                    logger.info(f"  [tag_id={tag_id}] å·²è·å– {len(all_events)} ä¸ªevents")

                # ç»ˆæ­¢æ¡ä»¶3: è¿”å›æ•°é‡ < è¯·æ±‚æ•°é‡ï¼ˆæœ€åä¸€é¡µï¼‰
                if len(events) < current_limit:
                    break

                offset += current_limit

            except requests.RequestException as e:
                logger.error(f"è·å–eventså¤±è´¥ (tag_id={tag_id}, offset={offset}): {e}")
                break

        return all_events

    def get_markets_by_tag(
        self,
        tag_id: str,
        active: bool = True,
        limit: int = 100,
        min_liquidity: float = 0,
        max_results: int = None,
        page_size: int = 100
    ) -> List[Market]:
        """
        æŒ‰tag_idè·å–æ‰€æœ‰ç›¸å…³markets

        è¿™æ˜¯ä»eventsç«¯ç‚¹è·å–çš„ï¼Œå› æ­¤æ¯ä¸ªmarketéƒ½ä¼šåŒ…å«
        event_descriptionå’Œtagsä¿¡æ¯ã€‚

        Args:
            tag_id: Tag ID (e.g., "21" for crypto)
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆæ—§è¡Œä¸ºå…¼å®¹ï¼‰
            min_liquidity: æœ€å°æµåŠ¨æ€§è¿‡æ»¤
            max_results: æœ€å¤§ç»“æœæ•°ï¼ˆNone=æ—§è¡Œä¸ºï¼Œ0=å…¨é‡ï¼Œ>0=æŒ‡å®šæ•°é‡ï¼‰
            page_size: æ¯é¡µå¤§å°

        Returns:
            Marketåˆ—è¡¨ï¼ˆåŒ…å«event_descriptionå’Œtagsï¼‰
        """
        markets = []

        events = self.get_events_by_tag(
            tag_id,
            active=active,
            limit=limit,
            max_results=max_results,
            page_size=page_size
        )

        for event in events:
            event_data = {
                "id": event.get("id"),
                "title": event.get("title"),
                "description": event.get("description", ""),
                "tags": event.get("tags", []),
                "resolutionSource": event.get("resolutionSource", "")
            }

            for market_data in event.get("markets", []):
                market = self._parse_market(market_data, event_data)
                if market:
                    # è¿‡æœŸå¸‚åœºè¿‡æ»¤
                    if market.is_expired:
                        continue
                    # æµåŠ¨æ€§è¿‡æ»¤
                    if min_liquidity > 0 and market.liquidity < min_liquidity:
                        continue
                    markets.append(market)

        return markets

    def get_markets_by_tag_slug(
        self,
        slug: str,
        active: bool = True,
        limit: int = 100,
        min_liquidity: float = 0,
        max_results: int = None,
        page_size: int = 100
    ) -> List[Market]:
        """
        æŒ‰tag slugè·å–æ‰€æœ‰ç›¸å…³marketsï¼ˆä¾¿æ·æ–¹æ³•ï¼‰

        Args:
            slug: Tag slug (e.g., "crypto", "politics")
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆæ—§è¡Œä¸ºå…¼å®¹ï¼‰
            min_liquidity: æœ€å°æµåŠ¨æ€§è¿‡æ»¤
            max_results: æœ€å¤§ç»“æœæ•°ï¼ˆNone=æ—§è¡Œä¸ºï¼Œ0=å…¨é‡ï¼Œ>0=æŒ‡å®šæ•°é‡ï¼‰
            page_size: æ¯é¡µå¤§å°

        Returns:
            Marketåˆ—è¡¨
        """
        # é¦–å…ˆè·å–tag_id
        try:
            self.rate_limiter.wait()
            url = f"{self.base_url}/tags/slug/{slug}"
            response = self.session.get(url, timeout=10)
            if response.status_code != 200:
                logger.error(f"Tag not found: {slug}")
                return []
            tag_data = response.json()
            tag_id = tag_data.get("id")
            if not tag_id:
                logger.error(f"Tag ID not found for: {slug}")
                return []
        except Exception as e:
            logger.error(f"Error fetching tag {slug}: {e}")
            return []

        return self.get_markets_by_tag(
            tag_id,
            active=active,
            limit=limit,
            min_liquidity=min_liquidity,
            max_results=max_results,
            page_size=page_size
        )

    # ============================================================
    # âœ… æ–°å¢: æŒ‰Event Slugè·å–EventåŠå…¶Markets
    # ============================================================

    def get_event_by_slug(self, slug: str) -> Optional[Dict]:
        """
        é€šè¿‡slugè·å–å•ä¸ªeventåŠå…¶æ‰€æœ‰å¸‚åœº

        Args:
            slug: Event slug (e.g., "bitcoin-price-on-january-6")

        Returns:
            Eventå­—å…¸ï¼ŒåŒ…å«marketsæ•°ç»„ï¼›å¦‚æœæœªæ‰¾åˆ°è¿”å›None

        Example:
            event = client.get_event_by_slug("bitcoin-price-on-january-6")
            markets = event.get("markets", [])
        """
        try:
            url = f"{self.base_url}/events"
            params = {"slug": slug}
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            events = response.json()
            return events[0] if events else None
        except requests.RequestException as e:
            logger.error(f"è·å–eventå¤±è´¥ (slug={slug}): {e}")
            return None

    def get_markets_in_event(
        self,
        event_slug: str,
        min_liquidity: float = 0
    ) -> List[Market]:
        """
        è·å–ä¸€ä¸ªeventä¸‹çš„æ‰€æœ‰å¸‚åœºå¹¶è§£æä¸ºMarketå¯¹è±¡

        è¿™æ˜¯æ£€æµ‹è·¨Eventå¥—åˆ©çš„å…³é”®æ–¹æ³•ã€‚ä¾‹å¦‚ï¼š
        - "bitcoin-price-on-january-6" eventæœ‰11ä¸ªåŒºé—´å¸‚åœº
        - "bitcoin-above-on-january-6" eventæœ‰10ä¸ªé˜ˆå€¼å¸‚åœº
        - å¯ä»¥å¯¹æ¯”ä¸¤ä¸ªeventä¸­çš„ç­‰ä»·å¸‚åœºï¼ˆå¦‚">98,000"ï¼‰

        Args:
            event_slug: Event slug
            min_liquidity: æœ€å°æµåŠ¨æ€§è¿‡æ»¤

        Returns:
            Marketåˆ—è¡¨
        """
        event = self.get_event_by_slug(event_slug)
        if not event:
            return []

        markets = []
        event_data = {
            "id": event.get("id"),
            "title": event.get("title"),
            "description": event.get("description", ""),
            "slug": event.get("slug"),
            "tags": event.get("tags", []),
            "resolutionSource": event.get("resolutionSource", "")
        }

        for market_data in event.get("markets", []):
            market = self._parse_market(market_data, event_data)
            if market:
                # è¿‡æœŸå¸‚åœºè¿‡æ»¤
                if market.is_expired:
                    continue
                if min_liquidity > 0 and market.liquidity < min_liquidity:
                    continue
                markets.append(market)

        return markets

    # ============================================================
    # åŸæœ‰æ–¹æ³•
    # ============================================================

    def get_markets_with_orderbook(self, limit: int = 100, active: bool = True,
                                   min_liquidity: float = 0, fetch_orderbook: bool = True) -> List[Market]:
        """
        è·å–å¸‚åœºåˆ—è¡¨å¹¶å¯é€‰åœ°è¡¥å……è®¢å•ç°¿æ•°æ®

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            min_liquidity: æœ€å°æµåŠ¨æ€§è¿‡æ»¤
            fetch_orderbook: æ˜¯å¦è·å–è®¢å•ç°¿æ•°æ® (ä¼šå¢åŠ APIè°ƒç”¨)

        Returns:
            Market åˆ—è¡¨
        """
        markets = self.get_markets(limit, active, min_liquidity)

        if fetch_orderbook:
            print(f"æ­£åœ¨è·å– {len(markets)} ä¸ªå¸‚åœºçš„è®¢å•ç°¿æ•°æ®...")
            for i, market in enumerate(markets):
                self.enrich_market_with_orderbook(market)
                if (i + 1) % 20 == 0:
                    print(f"  å·²å¤„ç† {i + 1}/{len(markets)} ä¸ªå¸‚åœº")

        return markets

    def fetch_crypto_markets(
        self,
        min_liquidity: float = 1000,
        search_queries: Optional[List[str]] = None
    ) -> List[Market]:
        """
        è·å–æ‰€æœ‰åŠ å¯†è´§å¸ç›¸å…³å¸‚åœºï¼ˆå¤šå…³é”®è¯ç»„åˆç­–ç•¥ï¼‰

        ç­–ç•¥ï¼š
        1. ä½¿ç”¨å¤šä¸ªå…³é”®è¯æœç´¢ï¼ˆBitcoin, BTC, Ethereumç­‰ï¼‰
        2. åˆå¹¶å»é‡
        3. æŒ‰æµåŠ¨æ€§æ’åº

        Args:
            min_liquidity: æœ€å°æµåŠ¨æ€§è¿‡æ»¤
            search_queries: æœç´¢å…³é”®è¯åˆ—è¡¨ï¼ˆé»˜è®¤ä½¿ç”¨åŠ å¯†è´§å¸å…³é”®è¯ï¼‰

        Returns:
            å»é‡åçš„åŠ å¯†è´§å¸å¸‚åœºåˆ—è¡¨
        """
        if search_queries is None:
            search_queries = [
                "Bitcoin", "BTC", "bitcoin", "btc",
                "Ethereum", "ETH", "ethereum", "eth",
                "crypto", "cryptocurrency", "Crypto"
            ]

        all_markets = []
        seen_ids = set()

        logging.info(f"ğŸ” ä½¿ç”¨ {len(search_queries)} ä¸ªå…³é”®è¯æœç´¢åŠ å¯†è´§å¸å¸‚åœº...")

        for query in search_queries:
            # ä½¿ç”¨å…³é”®è¯æœç´¢å¸‚åœº
            # æ³¨æ„ï¼šGamma APIå¯èƒ½ä¸æ”¯æŒç›´æ¥çš„å…³é”®è¯æœç´¢å‚æ•°
            # è¿™é‡Œæˆ‘ä»¬è·å–å¤§é‡å¸‚åœºï¼Œç„¶åé€šè¿‡å®¢æˆ·ç«¯è¿‡æ»¤
            markets_batch = self.get_markets(
                limit=200,  # æ¯æ¬¡è·å–200ä¸ª
                active=True,
                min_liquidity=min_liquidity
            )

            # å®¢æˆ·ç«¯è¿‡æ»¤ï¼šå…³é”®è¯åŒ¹é…
            query_lower = query.lower()
            filtered = [
                m for m in markets_batch
                if (query_lower in m.question.lower() or
                    query_lower in m.description.lower() or
                    query_lower in m.event_title.lower())
            ]

            # å»é‡
            for m in filtered:
                if m.id not in seen_ids:
                    all_markets.append(m)
                    seen_ids.add(m.id)

            logging.info(f"  å…³é”®è¯ '{query}': æ‰¾åˆ° {len(filtered)} ä¸ªå¸‚åœº")

        # æŒ‰æµåŠ¨æ€§æ’åºï¼ˆé™åºï¼‰
        all_markets.sort(key=lambda m: m.liquidity, reverse=True)

        logging.info(f"[OK] æ€»å…±æ‰¾åˆ° {len(all_markets)} ä¸ªåŠ å¯†è´§å¸å¸‚åœºï¼ˆå»é‡åï¼‰")

        return all_markets


# ============================================================
# å¸‚åœºé¢†åŸŸåˆ†ç±»å™¨
# ============================================================

class MarketDomainClassifier:
    """
    å¸‚åœºé¢†åŸŸåˆ†ç±»å™¨

    æ ¹æ®å¸‚åœºé—®é¢˜ã€æè¿°ã€äº‹ä»¶æ ‡é¢˜åˆ¤æ–­å¸‚åœºæ‰€å±é¢†åŸŸ
    """

    CRYPTO_KEYWORDS = [
        'bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'cryptocurrency',
        'solana', 'sol', 'cardano', 'ada', 'polkadot', 'dot',
        'dogecoin', 'doge', 'chainlink', 'link', 'ripple', 'xrp',
        'polygon', 'matic', 'avalanche', 'avax', 'binance', 'bnb'
    ]

    POLITICS_KEYWORDS = [
        'election', 'congress', 'senate', 'president', 'trump', 'biden',
        'republican', 'democrat', 'vote', 'ballot', 'policy'
    ]

    SPORTS_KEYWORDS = [
        'nba', 'nfl', 'mlb', 'world cup', 'super bowl', 'championship',
        'game', 'team', 'player', 'score', 'match', 'tournament'
    ]

    def classify(self, market: Market) -> str:
        """
        åˆ¤æ–­å¸‚åœºæ‰€å±é¢†åŸŸ

        Args:
            market: Market å¯¹è±¡

        Returns:
            é¢†åŸŸæ ‡è¯†: 'crypto', 'politics', 'sports', 'other'
        """
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å­—æ®µè¿›è¡Œåˆ¤æ–­
        text = (
            f"{market.question} {market.description} "
            f"{market.event_title}".lower()
        )

        # åŠ å¯†è´§å¸
        if any(kw in text for kw in self.CRYPTO_KEYWORDS):
            return 'crypto'

        # æ”¿æ²»
        if any(kw in text for kw in self.POLITICS_KEYWORDS):
            return 'politics'

        # ä½“è‚²
        if any(kw in text for kw in self.SPORTS_KEYWORDS):
            return 'sports'

        return 'other'


# ============================================================
# å¸‚åœºæ•°æ®ç¼“å­˜
# ============================================================

class MarketCache:
    """
    å¸‚åœºæ•°æ®ç¼“å­˜ç®¡ç†å™¨

    é¿å…é‡å¤APIè°ƒç”¨ï¼ŒåŠ é€Ÿæ•°æ®åŠ è½½
    """

    def __init__(self, cache_dir: str = "./cache", cache_ttl: int = 3600):
        """
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            cache_ttl: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        self.cache_dir = cache_dir
        self.cache_ttl = cache_ttl

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(cache_dir, exist_ok=True)

    def _get_cache_file(self, domain: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, f"{domain}_markets.json")

    def _is_cache_valid(self, cache_file: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not os.path.exists(cache_file):
            return False

        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        file_mtime = os.path.getmtime(cache_file)
        current_time = datetime.now().timestamp()
        age = current_time - file_mtime

        return age < self.cache_ttl

    def _load_cache(self, cache_file: str) -> List[Market]:
        """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½å¸‚åœºæ•°æ®"""
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            markets = []
            for item in data:
                try:
                    market = Market(**item)
                    markets.append(market)
                except Exception as e:
                    logging.warning(f"ç¼“å­˜æ•°æ®è§£æå¤±è´¥: {e}")
                    continue

            return markets

        except Exception as e:
            logging.warning(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            return []

    def _save_cache(self, cache_file: str, markets: List[Market]):
        """ä¿å­˜å¸‚åœºæ•°æ®åˆ°ç¼“å­˜æ–‡ä»¶"""
        try:
            data = [json_serialize(m) for m in markets]
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logging.info(f"ğŸ’¾ å·²ä¿å­˜ç¼“å­˜: {cache_file}")

        except Exception as e:
            logging.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def load_or_fetch(self, domain: str, fetcher, force_refresh: bool = False) -> List[Market]:
        """
        åŠ è½½ç¼“å­˜æˆ–è·å–æ–°æ•°æ®

        Args:
            domain: é¢†åŸŸæ ‡è¯†ï¼ˆ'crypto', 'politics'ç­‰ï¼‰
            fetcher: æ•°æ®è·å–å‡½æ•°ï¼ˆè¿”å› List[Market]ï¼‰
            force_refresh: å¼ºåˆ¶åˆ·æ–°ï¼Œè·³è¿‡ç¼“å­˜

        Returns:
            å¸‚åœºåˆ—è¡¨
        """
        cache_file = self._get_cache_file(domain)

        # ğŸ†• å¼ºåˆ¶åˆ·æ–°æ—¶è·³è¿‡ç¼“å­˜ï¼ˆv2.1æ–°å¢ï¼‰
        if force_refresh:
            logging.info(f"[REFRESH] å¼ºåˆ¶åˆ·æ–° {domain} å¸‚åœºæ•°æ®ï¼Œè·³è¿‡ç¼“å­˜")
            markets = fetcher()
            # ä¿å­˜åˆ°ç¼“å­˜
            if markets:
                self._save_cache(cache_file, markets)
            return markets

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if self._is_cache_valid(cache_file):
            logging.info(f"[CACHE] ä»ç¼“å­˜åŠ è½½ {domain} å¸‚åœºæ•°æ®")
            markets = self._load_cache(cache_file)
            if markets:
                return markets

        # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œé‡æ–°è·å–
        logging.info(f"ğŸŒ ä»APIè·å– {domain} å¸‚åœºæ•°æ®")
        markets = fetcher()

        # ä¿å­˜åˆ°ç¼“å­˜
        if markets:
            self._save_cache(cache_file, markets)

        return markets

    def clear_cache(self, domain: Optional[str] = None):
        """
        æ¸…é™¤ç¼“å­˜

        Args:
            domain: é¢†åŸŸæ ‡è¯†ï¼ŒNoneè¡¨ç¤ºæ¸…é™¤æ‰€æœ‰ç¼“å­˜
        """
        if domain:
            cache_file = self._get_cache_file(domain)
            if os.path.exists(cache_file):
                os.remove(cache_file)
                logging.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ {domain} ç¼“å­˜")
        else:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            for filename in os.listdir(self.cache_dir):
                if filename.endswith('_markets.json'):
                    file_path = os.path.join(self.cache_dir, filename)
                    os.remove(file_path)
            logging.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")


# ============================================================
# LLMåˆ†æå™¨ï¼ˆæ”¯æŒå¤šç§æä¾›å•†ï¼‰
# ============================================================

# æ—§ç‰ˆPromptï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰
ANALYSIS_PROMPT_LEGACY = """ä½ æ˜¯ä¸€ä¸ªä¸“é—¨åˆ†æé¢„æµ‹å¸‚åœºé€»è¾‘å…³ç³»çš„ä¸“å®¶ã€‚

è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªPolymarketé¢„æµ‹å¸‚åœºä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼š

**å¸‚åœºA:**
- é—®é¢˜: {question_a}
- æè¿°: {description_a}
- YESä»·æ ¼: ${price_a:.3f}
- ç»“ç®—æ¥æº: {source_a}

**å¸‚åœºB:**
- é—®é¢˜: {question_b}
- æè¿°: {description_b}
- YESä»·æ ¼: ${price_b:.3f}
- ç»“ç®—æ¥æº: {source_b}

è¯·åˆ¤æ–­é€»è¾‘å…³ç³»ç±»å‹ï¼ˆ6é€‰1ï¼‰ï¼š
1. IMPLIES_AB: Aå‘ç”Ÿâ†’Bå¿…å‘ç”Ÿï¼Œçº¦æŸP(B)â‰¥P(A)
2. IMPLIES_BA: Bå‘ç”Ÿâ†’Aå¿…å‘ç”Ÿï¼Œçº¦æŸP(A)â‰¥P(B)
3. EQUIVALENT: Aâ‰¡Bï¼Œçº¦æŸP(A)â‰ˆP(B)
4. MUTUAL_EXCLUSIVE: AâŠ•Bï¼Œçº¦æŸP(A)+P(B)â‰¤1
5. EXHAUSTIVE: å®Œå¤‡é›†çš„ä¸€éƒ¨åˆ†
6. UNRELATED: æ— é€»è¾‘å…³ç³»

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›ç­”ï¼ˆä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
```json
{{
  "relationship": "ç±»å‹",
  "confidence": 0.0-1.0,
  "reasoning": "åˆ†æç†ç”±",
  "probability_constraint": "çº¦æŸè¡¨è¾¾å¼",
  "edge_cases": ["è¾¹ç•Œæƒ…å†µ"],
  "resolution_compatible": trueæˆ–false
}}
```"""

# ä½¿ç”¨æ–°ç‰ˆPromptï¼ˆä»prompts.pyå¯¼å…¥ï¼‰
ANALYSIS_PROMPT = RELATIONSHIP_ANALYSIS_PROMPT_V2


class LLMAnalyzer:
    """LLMåˆ†æå™¨ - æ”¯æŒå¤šç§æä¾›å•†"""

    def __init__(self, config: AppConfig = None, profile_name: str = None, model_override: str = None):
        self.config = config
        self.use_llm = True
        self.client: Optional[BaseLLMClient] = None
        self.profile_name = profile_name
        self.model_name = model_override

        try:
            # æ–¹å¼1: å‘½ä»¤è¡ŒæŒ‡å®š --profile
            if profile_name:
                self._init_from_profile(profile_name, model_override)

            # æ–¹å¼2: config.json ä¸­æŒ‡å®šäº† providerï¼ˆä¼˜å…ˆäºè‡ªåŠ¨æ£€æµ‹ï¼‰
            elif config and config.llm.provider and config.llm.provider != "openai":
                # æ³¨æ„ï¼šopenaiæ˜¯é»˜è®¤å€¼ï¼Œå¦‚æœæ²¡æ”¹è¿‡å°±è·³è¿‡
                self._init_from_config(config, model_override)

            # æ–¹å¼3: config.json ä¸­æŒ‡å®šäº† api_key æˆ– api_base
            elif config and (config.llm.api_key or config.llm.api_base):
                self._init_from_config(config, model_override)

            # æ–¹å¼4: è‡ªåŠ¨æ£€æµ‹å·²é…ç½®çš„API Key
            else:
                self._init_from_auto_detect(model_override)

        except ValueError as e:
            print(f"[WARNING] LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            print("   å°†ä½¿ç”¨è§„åˆ™åŒ¹é…æ›¿ä»£LLMåˆ†æ")
            self.use_llm = False
        except Exception as e:
            print(f"[WARNING] LLMåˆå§‹åŒ–å¼‚å¸¸: {e}")
            self.use_llm = False

    def _init_from_profile(self, profile_name: str, model_override: str = None):
        """ä»profileé…ç½®åˆå§‹åŒ–"""
        from llm_config import get_llm_config_by_name, LLMScenario
        profile = get_llm_config_by_name(profile_name)
        if not profile:
            raise ValueError(f"æœªæ‰¾åˆ°é…ç½®: {profile_name}")

        if not profile.is_configured():
            raise ValueError(f"é…ç½® {profile_name} æœªè®¾ç½®API Key (éœ€è¦: {profile.api_key_env})")

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹è¦†ç›–ï¼Œä½¿ç”¨ç­–ç•¥æ‰«æåœºæ™¯çš„æ¨¡å‹
        if model_override is None:
            model = profile.get_model_for_scenario(LLMScenario.STRATEGY_SCAN)
        else:
            model = model_override

        self.client = create_llm_client(
            provider=profile.provider,
            api_base=profile.api_base,
            api_key=profile.get_api_key(),
            model=model,
            max_tokens=profile.max_tokens,
            temperature=profile.temperature,
        )
        self.profile_name = profile_name
        self.model_name = model
        print(f"[OK] LLMå·²åˆå§‹åŒ– (--profile): {profile_name} / {model}")

    def _init_from_config(self, config: AppConfig, model_override: str = None):
        """ä»config.jsonåˆå§‹åŒ–"""
        provider = config.llm.provider
        model = model_override or config.llm.model or None
        api_key = config.llm.api_key or None
        api_base = config.llm.api_base or None

        # å¦‚æœconfigæ²¡æœ‰api_keyï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        if not api_key:
            env_key_map = {
                "openai": "OPENAI_API_KEY",
                "anthropic": "ANTHROPIC_API_KEY",
                "deepseek": "DEEPSEEK_API_KEY",
                "aliyun": "DASHSCOPE_API_KEY",
                "zhipu": "ZHIPU_API_KEY",
                "siliconflow": "SILICONFLOW_API_KEY",
                "openai_compatible": "LLM_API_KEY",
            }
            env_var = env_key_map.get(provider, "LLM_API_KEY")
            api_key = os.getenv(env_var)

        self.client = create_llm_client(
            provider=provider,
            model=model,
            api_key=api_key,
            api_base=api_base,
            max_tokens=config.llm.max_tokens,
            temperature=config.llm.temperature,
        )
        self.model_name = self.client.config.model
        print(f"[OK] LLMå·²åˆå§‹åŒ– (config.json): {provider} / {self.client.config.model}")

    def _init_from_auto_detect(self, model_override: str = None):
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„LLMé…ç½®"""
        from llm_config import get_llm_config, LLMScenario
        profile = get_llm_config()

        if not profile:
            raise ValueError(
                "æœªæ£€æµ‹åˆ°å¯ç”¨çš„LLMé…ç½®ã€‚è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€:\n"
                "  1. è®¾ç½®ç¯å¢ƒå˜é‡ (å¦‚ DEEPSEEK_API_KEY)\n"
                "  2. ä½¿ç”¨ --profile å‚æ•° (å¦‚ --profile deepseek)\n"
                "  3. åœ¨ config.json ä¸­é…ç½® llm.provider å’Œ llm.api_key"
            )

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹è¦†ç›–ï¼Œä½¿ç”¨ç­–ç•¥æ‰«æåœºæ™¯çš„æ¨¡å‹
        if model_override is None:
            model = profile.get_model_for_scenario(LLMScenario.STRATEGY_SCAN)
        else:
            model = model_override

        self.client = create_llm_client(
            provider=profile.provider,
            api_base=profile.api_base,
            api_key=profile.get_api_key(),
            model=model,
            max_tokens=profile.max_tokens,
            temperature=profile.temperature,
        )
        self.profile_name = profile.name
        self.model_name = model
        print(f"[OK] LLMå·²åˆå§‹åŒ– (è‡ªåŠ¨æ£€æµ‹): {profile.name} / {model}")
    
    def analyze(self, market_a: Market, market_b: Market) -> Dict:
        """åˆ†æä¸¤ä¸ªå¸‚åœºçš„é€»è¾‘å…³ç³»"""
        if self.use_llm and self.client:
            return self._analyze_with_llm(market_a, market_b)
        else:
            return self._analyze_with_rules(market_a, market_b)
    
    def _analyze_with_llm(self, market_a: Market, market_b: Market) -> Dict:
        """ä½¿ç”¨LLMåˆ†æ"""
        # å°†Marketå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        market_a_dict = {
            "question": market_a.question,
            "description": market_a.description or "",
            "yes_price": market_a.yes_price,
            "end_date": market_a.end_date or "æœªæŒ‡å®š",
            "event_id": market_a.event_id or "æœªæŒ‡å®š",
            "resolution_source": market_a.resolution_source or "æœªæŒ‡å®š",
        }
        market_b_dict = {
            "question": market_b.question,
            "description": market_b.description or "",
            "yes_price": market_b.yes_price,
            "end_date": market_b.end_date or "æœªæŒ‡å®š",
            "event_id": market_b.event_id or "æœªæŒ‡å®š",
            "resolution_source": market_b.resolution_source or "æœªæŒ‡å®š",
        }

        # ä½¿ç”¨æ–°ç‰ˆPromptæ ¼å¼åŒ–å‡½æ•°
        prompt = format_analysis_prompt(
            market_a_dict,
            market_b_dict,
            PromptConfig(version="v2")
        )

        try:
            response = self.client.chat(prompt)
            content = response.content

            # æå–JSON
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            result = json.loads(content.strip())

            # æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            normalized = self._normalize_llm_response(result)
            return normalized

        except json.JSONDecodeError as e:
            # ä¿å­˜å®Œæ•´LLMå“åº”ç”¨äºè°ƒè¯•
            self._save_llm_error_response(market_a, market_b, response.content, content, str(e))

            error_msg = (
                f"JSONè§£æå¤±è´¥\n"
                f"  é”™è¯¯ä¿¡æ¯: {e}\n"
                f"  å¸‚åœºA: {market_a.question[:50]}...\n"
                f"  å¸‚åœºB: {market_b.question[:50]}...\n"
                f"  å®Œæ•´å“åº”å·²ä¿å­˜åˆ°: output/llm_errors/"
            )
            logger.error(error_msg)
            print(f"    JSONè§£æå¤±è´¥: {e} (å®Œæ•´å“åº”å·²ä¿å­˜)")
            return self._analyze_with_rules(market_a, market_b)
        except Exception as e:
            error_msg = (
                f"LLMåˆ†æå¤±è´¥\n"
                f"  é”™è¯¯ç±»å‹: {type(e).__name__}\n"
                f"  é”™è¯¯ä¿¡æ¯: {e}\n"
                f"  å¸‚åœºA: {market_a.question[:50]}...\n"
                f"  å¸‚åœºB: {market_b.question[:50]}...\n"
                f"  å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}"
            )
            logger.error(error_msg)
            print(f"    LLMåˆ†æå¤±è´¥: {e}")
            return self._analyze_with_rules(market_a, market_b)

    def _normalize_llm_response(self, result: Dict) -> Dict:
        """æ ‡å‡†åŒ–LLMå“åº”æ ¼å¼"""
        # å¤„ç†åµŒå¥—çš„reasoningç»“æ„
        reasoning = result.get("reasoning", "")
        if isinstance(reasoning, dict):
            reasoning = reasoning.get("conclusion", "") or reasoning.get("logical_analysis", "")

        relationship = result.get("relationship", "UNRELATED").upper()
        confidence = result.get("confidence", 0.5)

        # æ„å»ºä¸´æ—¶ç»“æœç”¨äºä¸€è‡´æ€§æ£€æŸ¥
        temp_result = {
            'relationship': relationship,
            'reasoning': reasoning,
            'confidence': confidence
        }

        # âœ… è°ƒç”¨ä¸€è‡´æ€§æ£€æŸ¥æ–¹æ³•
        is_consistent, consistency_error = self._validate_llm_response_consistency(temp_result)

        if not is_consistent:
            print(f"    [WARNING] LLMè¾“å‡ºä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {consistency_error}")
            print(f"       é™çº§ä¸º INDEPENDENT ä»¥é˜²æ­¢å‡å¥—åˆ©")
            # é™çº§ä¸º INDEPENDENT
            relationship = "INDEPENDENT"
            confidence = 0.0

        # ä¸€è‡´æ€§æ£€æŸ¥: æ£€æµ‹ relationship ä¸ reasoning æ˜¯å¦çŸ›ç›¾ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºåŒé‡æ£€æŸ¥ï¼‰
        reasoning_upper = reasoning.upper() if isinstance(reasoning, str) else ""
        inconsistency_detected = False

        if relationship == "IMPLIES_AB" and "IMPLIES_BA" in reasoning_upper:
            print(f"    [WARNING] LLMå“åº”ä¸ä¸€è‡´: relationship={relationship}, ä½†reasoningæåˆ°IMPLIES_BA")
            inconsistency_detected = True
        elif relationship == "IMPLIES_BA" and "IMPLIES_AB" in reasoning_upper and "IMPLIES_BA" not in reasoning_upper:
            print(f"    [WARNING] LLMå“åº”ä¸ä¸€è‡´: relationship={relationship}, ä½†reasoningæåˆ°IMPLIES_AB")
            inconsistency_detected = True

        # å¦‚æœæ£€æµ‹åˆ°ä¸ä¸€è‡´ï¼Œé™ä½ç½®ä¿¡åº¦
        if inconsistency_detected:
            confidence = min(confidence, 0.5)  # é™ä½åˆ°æœ€å¤š0.5

        # æå–å…³é”®å­—æ®µ
        normalized = {
            "relationship": relationship,
            "confidence": confidence,
            "reasoning": reasoning,
            "probability_constraint": result.get("probability_constraint"),
            "edge_cases": result.get("edge_cases", []),
            "resolution_compatible": result.get("resolution_check", {}).get("rules_compatible", True)
                                      if isinstance(result.get("resolution_check"), dict)
                                      else result.get("resolution_compatible", True),
            "constraint_violated": result.get("constraint_violated", False),
            "violation_amount": result.get("violation_amount", 0),
            "arbitrage_viable": result.get("arbitrage_viable", False),
            "inconsistency_detected": inconsistency_detected,  # æ ‡è®°ä¸ä¸€è‡´
            "is_consistent": is_consistent,  # âœ… æ–°å¢ï¼šä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
            "consistency_error": consistency_error if not is_consistent else None  # âœ… æ–°å¢ï¼šé”™è¯¯ä¿¡æ¯
        }

        return normalized

    
    def _analyze_with_rules(self, market_a: Market, market_b: Market) -> Dict:
        """ä½¿ç”¨è§„åˆ™åŒ¹é…åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        q_a = market_a.question.lower()
        q_b = market_b.question.lower()
        
        # è§„åˆ™1: ä¸ªäººå€™é€‰äºº vs æ”¿å…š
        candidates = ["trump", "biden", "harris", "desantis", "haley", "newsom", "vance"]
        parties = ["republican", "democrat", "gop", "dem"]
        
        candidate_in_a = any(c in q_a for c in candidates)
        candidate_in_b = any(c in q_b for c in candidates)
        party_in_a = any(p in q_a for p in parties)
        party_in_b = any(p in q_b for p in parties)
        
        if candidate_in_a and party_in_b and not candidate_in_b:
            if ("republican" in q_b and any(c in q_a for c in ["trump", "desantis", "haley", "vance"])) or \
               ("democrat" in q_b and any(c in q_a for c in ["biden", "harris", "newsom"])):
                return {
                    "relationship": "IMPLIES_AB",
                    "confidence": 0.9,
                    "reasoning": "ä¸ªäººå€™é€‰äººè·èƒœæ„å‘³ç€å…¶æ”¿å…šè·èƒœ",
                    "probability_constraint": "P(Party) >= P(Candidate)",
                    "edge_cases": ["å€™é€‰äººå¯èƒ½é€€å‡º", "ç‹¬ç«‹å‚é€‰"],
                    "resolution_compatible": True,
                }
        
        # è§„åˆ™2: å¤ºå†  vs è¿›å­£åèµ›
        if "champion" in q_a and "playoff" in q_b:
            return {
                "relationship": "IMPLIES_AB",
                "confidence": 0.99,
                "reasoning": "å¤ºå† å¿…é¡»å…ˆè¿›å…¥å­£åèµ›",
                "probability_constraint": "P(Playoffs) >= P(Championship)",
                "edge_cases": [],
                "resolution_compatible": True,
            }
        
        if "playoff" in q_a and "champion" in q_b:
            return {
                "relationship": "IMPLIES_BA",
                "confidence": 0.99,
                "reasoning": "å¤ºå† å¿…é¡»å…ˆè¿›å…¥å­£åèµ›",
                "probability_constraint": "P(Playoffs) >= P(Championship)",
                "edge_cases": [],
                "resolution_compatible": True,
            }
        
        # è§„åˆ™3: åŒä¸€äº‹ä»¶çš„äº’æ–¥ç»“æœ
        if market_a.event_id and market_a.event_id == market_b.event_id:
            return {
                "relationship": "MUTUAL_EXCLUSIVE",
                "confidence": 0.8,
                "reasoning": "åŒä¸€äº‹ä»¶ä¸‹çš„ä¸åŒç»“æœé€šå¸¸äº’æ–¥",
                "probability_constraint": "å¯èƒ½æ˜¯å®Œå¤‡é›†çš„ä¸€éƒ¨åˆ†",
                "edge_cases": ["éœ€è¦æ£€æŸ¥æ˜¯å¦æ„æˆå®Œå¤‡é›†"],
                "resolution_compatible": True,
            }
        
        # é»˜è®¤
        return {
            "relationship": "UNRELATED",
            "confidence": 0.5,
            "reasoning": "æœªèƒ½é€šè¿‡è§„åˆ™åŒ¹é…è¯†åˆ«é€»è¾‘å…³ç³»",
            "probability_constraint": None,
            "edge_cases": ["éœ€è¦äººå·¥åˆ†æ"],
            "resolution_compatible": None,
        }
    
    def _validate_llm_response_consistency(self, llm_result: dict) -> tuple[bool, str]:
        """
        éªŒè¯ LLM è¾“å‡ºçš„ consistency

        æ£€æŸ¥ reasoning å­—æ®µæ˜¯å¦ä¸ relationship åˆ†ç±»çŸ›ç›¾

        Args:
            llm_result: LLM è¿”å›çš„åˆ†æç»“æœ
                {
                    'relationship': 'IMPLIES_AB',
                    'reasoning': '...',
                    'confidence': 0.95
                }

        Returns:
            (is_valid, error_message)
            - is_valid: True è¡¨ç¤ºä¸€è‡´ï¼ŒFalse è¡¨ç¤ºå‘ç°çŸ›ç›¾
            - error_message: çŸ›ç›¾æè¿°

        Examples:
             # çŸ›ç›¾æ¡ˆä¾‹ï¼šreasoning è¯´äº’æ–¥ï¼Œä½† relationship æ˜¯ IMPLIES
             result = {
            ...     'relationship': 'IMPLIES_AB',
            ...     'reasoning': 'These markets are mutually exclusive'
            ... }
             is_valid, msg = analyzer._validate_llm_response_consistency(result)
             assert not is_valid
             assert 'mutual' in msg.lower()
        """
        relationship = llm_result.get('relationship', '')
        reasoning = llm_result.get('reasoning', '').lower()

        # å®šä¹‰çŸ›ç›¾æ¨¡å¼
        contradictions = {
            'IMPLIES_AB': [
                'mutual', 'exclusive', 'independent', 'unrelated',
                'çŸ›ç›¾', 'äº’æ–¥', 'æ— å…³', 'ç‹¬ç«‹'
            ],
            'IMPLIES_BA': [
                'mutual', 'exclusive', 'independent', 'unrelated',
                'çŸ›ç›¾', 'äº’æ–¥', 'æ— å…³', 'ç‹¬ç«‹'
            ],
            'EQUIVALENT': [
                'different', 'exclusive', 'independent', 'opposite',
                'ä¸åŒ', 'äº’æ–¥', 'çŸ›ç›¾', 'ç›¸å'
            ],
            'MUTUAL_EXCLUSIVE': [
                'implies', 'equivalent', 'same event', 'identical',
                'è•´å«', 'ç­‰ä»·', 'ç›¸åŒ', 'ä¸€è‡´'
            ],
        }

        # æ£€æŸ¥æ˜¯å¦çŸ›ç›¾
        if relationship in contradictions:
            forbidden_terms = contradictions[relationship]
            for term in forbidden_terms:
                if term in reasoning:
                    return False, (
                        f"LLM è¾“å‡ºçŸ›ç›¾: relationship={relationship}, "
                        f"ä½† reasoning åŒ…å« '{term}'"
                    )

        return True, ""

    def _save_llm_error_response(self, market_a: Market, market_b: Market,
                                 raw_response: str, extracted_content: str,
                                 error_msg: str):
        """
        ä¿å­˜LLMè§£æå¤±è´¥çš„å®Œæ•´å“åº”ç”¨äºè°ƒè¯•

        Args:
            market_a: å¸‚åœºA
            market_b: å¸‚åœºB
            raw_response: LLMåŸå§‹å®Œæ•´å“åº”
            extracted_content: æå–å‡ºçš„JSONå†…å®¹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯çš„ï¼‰
            error_msg: JSONè§£æé”™è¯¯ä¿¡æ¯
        """
        import os
        from datetime import datetime

        # åˆ›å»ºé”™è¯¯ç›®å½•
        error_dir = "output/llm_errors"
        os.makedirs(error_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œå¸‚åœºIDï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        safe_id_a = market_a.question[:30].replace(" ", "_").replace("/", "_") if market_a.question else "unknown"
        safe_id_b = market_b.question[:30].replace(" ", "_").replace("/", "_") if market_b.question else "unknown"
        filename = f"{timestamp}_{safe_id_a}_{safe_id_b}.txt"
        filepath = os.path.join(error_dir, filename)

        # å‡†å¤‡æ—¥å¿—å†…å®¹
        log_content = f"""=== LLM JSONè§£æé”™è¯¯æ—¥å¿— ===
æ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
é”™è¯¯ä¿¡æ¯: {error_msg}

=== å¸‚åœºA ===
ID: {market_a.id or 'N/A'}
é—®é¢˜: {market_a.question}
YESä»·æ ¼: {market_a.yes_price}
Event ID: {market_a.event_id or 'N/A'}

=== å¸‚åœºB ===
ID: {market_b.id or 'N/A'}
é—®é¢˜: {market_b.question}
YESä»·æ ¼: {market_b.yes_price}
Event ID: {market_b.event_id or 'N/A'}

=== LLMåŸå§‹å“åº” ===
{raw_response}

=== æå–çš„JSONå†…å®¹ï¼ˆè§£æå¤±è´¥ï¼‰ ===
{extracted_content}

=== ç»“æŸ ===
"""

        # å†™å…¥æ–‡ä»¶
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(log_content)
        except Exception as write_error:
            logger.warning(f"æ— æ³•ä¿å­˜LLMé”™è¯¯æ—¥å¿—: {write_error}")

    def analyze_cluster(self, cluster_id: str, markets: List[Any]) -> Dict[str, Any]:
        """
        [Phase 5.2] æ‰¹é‡åˆ†æè¯­ä¹‰èšç±»ç°‡
        """
        if not self.use_llm or not self.client:
            return {"relationships": [], "synthetic_opportunities": []}

        from prompts import CLUSTER_ANALYSIS_PROMPT

        # 1. å‡†å¤‡å¸‚åœºåˆ—è¡¨æ‘˜è¦ (Phase 5.4 æ€§èƒ½ä¼˜åŒ–ï¼šå¤§å‹ç°‡é‡‡æ ·)
        max_analyze_size = 25
        if len(markets) > max_analyze_size:
            logging.info(f"ç°‡è§„æ¨¡è¿‡å¤§ ({len(markets)})ï¼Œä»…åˆ†æå‰ {max_analyze_size} ä¸ªæ ¸å¿ƒå¸‚åœº")
            # å°è¯•æŒ‰æµåŠ¨æ€§æ’åºï¼ˆå¦‚æœå±æ€§å­˜åœ¨ï¼‰
            try:
                target_markets = sorted(markets, key=lambda x: getattr(x, 'liquidity', 0), reverse=True)[:max_analyze_size]
            except Exception:
                target_markets = markets[:max_analyze_size]
        else:
            target_markets = markets

        market_list_str = ""
        avg_liquidity = 0
        for m in target_markets:
            market_list_str += f"- ID: {m.id} | Question: {m.question} | Price: ${m.yes_price:.3f} | End: {m.end_date}\n"
            avg_liquidity += getattr(m, 'liquidity', 0)

        avg_liquidity /= len(target_markets) if target_markets else 1

        # 2. å¡«å……å¹¶å‘é€ Prompt
        prompt = CLUSTER_ANALYSIS_PROMPT.format(
            cluster_id=cluster_id,
            cluster_size=len(target_markets),
            avg_liquidity=avg_liquidity,
            market_list=market_list_str
        )

        try:
            # âœ… ä¿®æ­£ï¼šä½¿ç”¨ chat æ–¹æ³• (Phase 5.4 ä¿®å¤)
            response = self.client.chat(prompt)
            # æå– JSON å†…å®¹
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            return json.loads(content)
        except Exception as e:
            logger.error(f"æ‰¹é‡èšç±»åˆ†æå¤±è´¥: {e}")
            return {"relationships": [], "synthetic_opportunities": []}

    def close(self):
        """å…³é—­LLMå®¢æˆ·ç«¯"""
        if self.client:
            self.client.close()


# ============================================================
# å¥—åˆ©æ£€æµ‹å™¨
# ============================================================

class ArbitrageDetector:
    """å¥—åˆ©æœºä¼šæ£€æµ‹å™¨"""

    def __init__(self, config: AppConfig, llm_analyzer: 'LLMAnalyzer' = None):
        self.min_profit_pct = config.scan.min_profit_pct
        self.min_confidence = config.scan.min_confidence

        # âœ… æ–°å¢ï¼šåˆå§‹åŒ–æ•°å­¦éªŒè¯å™¨
        self.math_validator = MathValidator()
        print(f"[OK] MathValidator å·²åˆå§‹åŒ–")

        # âœ… æ–°å¢ï¼šLLM åˆ†æå™¨å¼•ç”¨ï¼ˆç”¨äºå®Œå¤‡é›†éªŒè¯ï¼‰
        self.llm_analyzer = llm_analyzer

    def verify_exhaustive_set_with_llm(self, markets: List[Market]) -> Dict:
        """
        ä½¿ç”¨ LLM éªŒè¯å¸‚åœºç»„æ˜¯å¦æ„æˆå®Œå¤‡é›†

        Args:
            markets: å¾…éªŒè¯çš„å¸‚åœºåˆ—è¡¨

        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼š
            {
                "is_valid": bool,
                "is_mutually_exclusive": bool,
                "is_complete": bool,
                "missing_options": [],
                "overlap_risks": [],
                "confidence": float,
                "reasoning": str
            }
        """
        if not self.llm_analyzer or not self.llm_analyzer.use_llm:
            # æ²¡æœ‰ LLMï¼Œè¿”å›é»˜è®¤é€šè¿‡ï¼ˆä¾èµ–è§„åˆ™éªŒè¯ï¼‰
            return {
                "is_valid": True,
                "confidence": 0.5,
                "reasoning": "æœªé…ç½®LLMï¼Œè·³è¿‡è¯­ä¹‰éªŒè¯"
            }

        # æ„å»ºéªŒè¯ Prompt
        from prompts import format_exhaustive_prompt

        event_title = markets[0].event_title or markets[0].event_id or "æœªçŸ¥äº‹ä»¶"
        markets_dict = [
            {"question": m.question, "yes_price": m.yes_price}
            for m in markets
        ]
        total_price = sum(m.yes_price for m in markets)

        prompt = format_exhaustive_prompt(event_title, markets_dict, total_price)

        try:
            response = self.llm_analyzer.client.chat(prompt)
            content = response.content

            # æå– JSON
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            result = json.loads(content.strip())

            # æ ‡å‡†åŒ–ç»“æœ
            return {
                "is_valid": result.get("is_valid_exhaustive_set", False),
                "is_mutually_exclusive": result.get("is_mutually_exclusive", False),
                "is_complete": result.get("is_complete", False),
                "missing_options": result.get("missing_options", []),
                "overlap_risks": result.get("overlap_risks", []),
                "confidence": result.get("confidence", 0.5),
                "reasoning": result.get("reasoning", ""),
                "arbitrage_safe": result.get("arbitrage_safe", False)
            }

        except json.JSONDecodeError as e:
            market_questions = [m.question[:30] + "..." for m in markets[:3]]
            error_msg = (
                f"LLMå®Œå¤‡é›†éªŒè¯JSONè§£æå¤±è´¥\n"
                f"  é”™è¯¯ä¿¡æ¯: {e}\n"
                f"  äº‹ä»¶: {event_title}\n"
                f"  å¸‚åœºæ•°é‡: {len(markets)}\n"
                f"  å¸‚åœºæ ·ä¾‹: {market_questions}\n"
                f"  åŸå§‹å“åº”: {content[:200] if 'content' in dir() else 'N/A'}..."
            )
            logger.error(error_msg)
            print(f"    [WARNING] LLMå®Œå¤‡é›†éªŒè¯JSONè§£æå¤±è´¥: {e}")
            return {
                "is_valid": False,
                "confidence": 0.0,
                "reasoning": f"JSONè§£æå¤±è´¥: {e}"
            }
        except Exception as e:
            market_questions = [m.question[:30] + "..." for m in markets[:3]]
            error_msg = (
                f"LLMå®Œå¤‡é›†éªŒè¯å¤±è´¥\n"
                f"  é”™è¯¯ç±»å‹: {type(e).__name__}\n"
                f"  é”™è¯¯ä¿¡æ¯: {e}\n"
                f"  äº‹ä»¶: {event_title}\n"
                f"  å¸‚åœºæ•°é‡: {len(markets)}\n"
                f"  å¸‚åœºæ ·ä¾‹: {market_questions}\n"
                f"  å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}"
            )
            logger.error(error_msg)
            print(f"    [WARNING] LLMå®Œå¤‡é›†éªŒè¯å¤±è´¥: {e}")
            return {
                "is_valid": False,
                "confidence": 0.0,
                "reasoning": f"éªŒè¯å¤±è´¥: {e}"
            }



# ============================================================
# ä¸»æ‰«æå™¨
# ============================================================

class ArbitrageScanner:
    """
    ä¸»æ‰«æå™¨ - å‘é‡åŒ–é©±åŠ¨ç‰ˆæœ¬

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. å‘é‡åŒ–æ¨¡å¼ï¼ˆæ–°ï¼‰ï¼šæŒ‰é¢†åŸŸè·å–å¸‚åœº â†’ è¯­ä¹‰èšç±» â†’ èšç±»å†…å…¨è‡ªåŠ¨åˆ†æ
    2. ä¼ ç»Ÿæ¨¡å¼ï¼ˆå…¼å®¹ï¼‰ï¼šå…³é”®è¯æœç´¢ â†’ Jaccardç›¸ä¼¼åº¦ â†’ LLMåˆ†æ
    """

    def __init__(
        self,
        config: AppConfig,
        profile_name: str = None,
        model_override: str = None,
        run_mode: RunMode = RunMode.PRODUCTION
    ):
        """
        Args:
            config: é…ç½®å¯¹è±¡
            profile_name: LLMé…ç½®åç§°
            model_override: æ¨¡å‹è¦†ç›–
            run_mode: è¿è¡Œæ¨¡å¼ (DEBUG=æš‚åœç¡®è®¤, PRODUCTION=è‡ªåŠ¨ä¿å­˜)
        """
        self.config = config
        self.profile_name = profile_name
        self.model_override = model_override

        # è¿è¡Œæ¨¡å¼
        self.run_mode = run_mode

        # æˆå‘˜å˜é‡
        self.false_positive_log = []   # è¯¯æŠ¥æ—¥å¿—
        self.opportunity_counter = 0    # æœºä¼šè®¡æ•°å™¨
        self.discovered_opportunities = []  # å‘ç°çš„æ‰€æœ‰æœºä¼šï¼ˆç”¨äºè‡ªåŠ¨ä¿å­˜ï¼‰

        # åŸºç¡€ç»„ä»¶
        self.client = PolymarketClient()
        self.analyzer = LLMAnalyzer(config, profile_name=profile_name, model_override=model_override)
        # âœ… ä¼ å…¥ LLM åˆ†æå™¨ï¼Œç”¨äºå®Œå¤‡é›†è¯­ä¹‰éªŒè¯
        self.detector = ArbitrageDetector(config, llm_analyzer=self.analyzer)

        # å¸‚åœºç¼“å­˜å’Œåˆ†ç±»ç»„ä»¶ï¼ˆç­–ç•¥ç³»ç»Ÿéœ€è¦ï¼‰
        self.market_cache = MarketCache(
            cache_dir=config.output.cache_dir,
            cache_ttl=getattr(config.scan, 'cache_ttl', 3600)
        )
        self.domain_classifier = MarketDomainClassifier()

        # âœ… æ–°å¢ï¼šè¯­ä¹‰èšç±»å™¨ (Phase 2.6)
        try:
            self.clusterer = SemanticClusterer()
        except Exception as e:
            logging.warning(f"æ— æ³•åˆå§‹åŒ–è¯­ä¹‰èšç±»å™¨: {e}ï¼Œå°†ç¦ç”¨è¯­ä¹‰èšç±»åŠŸèƒ½")
            self.clusterer = None

        # âœ… æ–°å¢ï¼šåŠ¨æ€åˆ†ç±»ç»„ä»¶ (v3.1)
        self.category_discovery = None
        self.use_dynamic_categories = getattr(config.scan, 'use_dynamic_categories', False)

        # âœ… æ–°å¢ï¼šéªŒè¯å¼•æ“ (v2.5)
        self.validation_engine = ValidationEngine(config)

        # âœ… æ–°å¢ï¼šé€šçŸ¥ç³»ç»Ÿ (Phase 3.3)
        self.notifier = ArbitrageNotifier(config)

        # âœ… æ–°å¢ï¼šæ—¶é—´åºåˆ—æ•°æ®è®°å½•å™¨ (Phase 6.1)
        self.recorder = TimeSeriesRecorder(
            db_path=Path(self.config.output.output_dir) / "market_history.db"
        )

        # âœ… æ–°å¢ï¼šWebSocket å®æ—¶å®¢æˆ·ç«¯ (Phase 8)
        self.ws_client = PolymarketWSClient()
        self._ws_task = None

        # âœ… æ–°å¢ï¼šæ‰§è¡Œå¼•æ“ (Phase 4.1)
        # ğŸ†• ä¼ å…¥ recorder å’Œ WebSocket ç¼“å­˜ (Phase 8)
        self.execution_engine = ExecutionEngine(self.client, config, self.recorder, self.ws_client.cache)

        logging.info("âœ… ç­–ç•¥ç³»ç»Ÿç»„ä»¶ã€éªŒè¯å¼•æ“ã€é€šçŸ¥å™¨ã€æ‰§è¡Œå¼•æ“ã€èšç±»å™¨ã€è®°å½•å™¨ä¸ WS å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")

    def start_websocket(self, token_ids: List[str] = None):
        """
        [Phase 8] å¯åŠ¨ WebSocket å®æ—¶ç›‘å¬ä»»åŠ¡
        """
        import threading
        import asyncio

        if self._ws_task and not self._ws_task.done():
            if token_ids:
                asyncio.run_coroutine_threadsafe(self.ws_client.subscribe(token_ids), self._loop)
            return

        def run_ws_loop():
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            if token_ids:
                self.ws_client.assets_ids.extend(token_ids)
            self._loop.run_until_complete(self.ws_client.connect())

        self._ws_thread = threading.Thread(target=run_ws_loop, daemon=True)
        self._ws_thread.start()
        logging.info(f"WebSocket ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨ï¼Œé¢„è®¢é˜… {len(token_ids) if token_ids else 0} ä¸ªèµ„äº§")

    def stop_websocket(self):
        """åœæ­¢ WebSocket ç›‘å¬"""
        self.ws_client.stop()
        if hasattr(self, '_loop'):
            self._loop.stop()
        logging.info("WebSocket ç›‘å¬å·²åœæ­¢")

    def _load_tag_categories(self) -> Dict[str, List[str]]:
        """
        åŠ è½½æ ‡ç­¾åˆ†ç±»æ–‡ä»¶

        Returns:
            å­—å…¸ï¼Œkeyä¸ºç±»åˆ«åï¼Œvalueä¸ºtag slugåˆ—è¡¨
        """
        tag_categories_file = Path(__file__).parent / "data" / "tag_categories.json"
        if not tag_categories_file.exists():
            logging.warning(f"[WARNING] æ ‡ç­¾åˆ†ç±»æ–‡ä»¶ä¸å­˜åœ¨: {tag_categories_file}")
            return {}

        try:
            with open(tag_categories_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get("categories", {})
        except Exception as e:
            logging.error(f"[ERROR] åŠ è½½æ ‡ç­¾åˆ†ç±»å¤±è´¥: {e}")
            return {}

    def _expand_subcategory(self, subcat: str, all_tags: List[str]) -> List[str]:
        """
        æ‰©å±•å­ç±»åˆ«ï¼Œè‡ªåŠ¨åŒ…å«ç›¸å…³æ ‡ç­¾

        ä¾‹å¦‚: bitcoin -> [bitcoin, bitcoin-prices, bitcoin-volatility, strategic-bitcoin-reserve, ...]

        Args:
            subcat: å­ç±»åˆ«åç§°ï¼ˆå¦‚ "bitcoin"ï¼‰
            all_tags: è¯¥é¢†åŸŸæ‰€æœ‰å¯ç”¨çš„tagåˆ—è¡¨

        Returns:
            åŒ…å«è¯¥å­ç±»åˆ«çš„æ‰€æœ‰ç›¸å…³tagåˆ—è¡¨
        """
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«å­ç±»åˆ«åç§°çš„æ ‡ç­¾ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        subcat_lower = subcat.lower()
        related = [tag for tag in all_tags if subcat_lower in tag.lower()]

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ ‡ç­¾ï¼Œè‡³å°‘è¿”å›åŸå§‹è¾“å…¥ï¼ˆå¯èƒ½æ˜¯æ— æ•ˆçš„ï¼Œåç»­ä¼šéªŒè¯ï¼‰
        return related if related else [subcat]

    # ============================================================
    # ğŸ†• åŠ¨æ€åˆ†ç±»ç®¡ç†æ–¹æ³• (v3.1æ–°å¢)
    # ============================================================

    def get_category_discovery(self) -> CategoryDiscovery:
        """
        è·å–æˆ–åˆå§‹åŒ–åˆ†ç±»å‘ç°å¼•æ“

        Returns:
            CategoryDiscovery å®ä¾‹
        """
        if self.category_discovery is None:
            self.category_discovery = CategoryDiscovery(
                polymarket_client=self.client,
                llm_profile_name=self.profile_name,
                output=ScannerOutput() if CLI_AVAILABLE else None
            )
        return self.category_discovery

    def get_available_categories(self, force_refresh: bool = False) -> List[CategoryInfo]:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„æ‰«æç±»åˆ«

        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶é‡æ–°å‘ç°

        Returns:
            CategoryInfo å¯¹è±¡åˆ—è¡¨
        """
        if self.use_dynamic_categories:
            try:
                discovery = self.get_category_discovery()
                cache = discovery.discover_categories(
                    max_categories=getattr(self.config.scan, 'category_discovery_max', 12),
                    min_tags_per_category=getattr(self.config.scan, 'category_discovery_min_tags', 5),
                    force_refresh=force_refresh
                )

                # è½¬æ¢ä¸º CategoryInfo å¯¹è±¡åˆ—è¡¨
                categories = []
                for cat_dict in cache.categories:
                    # å¤„ç†ä» JSON åŠ è½½æ—¶çš„ set/list è½¬æ¢
                    included_tags = cat_dict.get('included_tags', set())
                    if isinstance(included_tags, list):
                        included_tags = set(included_tags)

                    categories.append(CategoryInfo(
                        id=cat_dict['id'],
                        name_zh=cat_dict['name_zh'],
                        name_en=cat_dict['name_en'],
                        description=cat_dict['description'],
                        representative_tags=cat_dict['representative_tags'],
                        market_count=cat_dict['market_count'],
                        discovery_confidence=cat_dict['discovery_confidence'],
                        created_at=cat_dict['created_at'],
                        included_tags=included_tags,
                        icon=cat_dict.get('icon', ''),
                        priority=cat_dict.get('priority', 999)
                    ))
                return sorted(categories, key=lambda x: x.priority)
            except Exception as e:
                logging.error(f"[ERROR] åŠ¨æ€åˆ†ç±»å‘ç°å¤±è´¥: {e}")
                logging.info("å›é€€åˆ°å›ºå®šåˆ†ç±»æ¨¡å¼")
                return self._get_fixed_domain_categories()
        else:
            return self._get_fixed_domain_categories()

    def _get_fixed_domain_categories(self) -> List[CategoryInfo]:
        """
        è·å–ç¡¬ç¼–ç çš„å›ºå®šåˆ†ç±»ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰

        Returns:
            CategoryInfo åˆ—è¡¨
        """
        tag_categories = self._load_tag_categories()
        if not tag_categories:
            return []

        # æ˜ å°„ä¸­æ–‡åç§°å’Œå›¾æ ‡
        meta = {
            "crypto": ("åŠ å¯†è´§å¸", "Cryptocurrency", "â‚¿", 1),
            "politics": ("æ”¿æ²»", "Politics", "ğŸ›ï¸", 2),
            "sports": ("ä½“è‚²", "Sports", "ğŸ€", 3),
            "economics": ("ç»æµ", "Economics", "ğŸ“ˆ", 4),
            "entertainment": ("å¨±ä¹", "Entertainment", "ğŸ¬", 5),
            "other": ("å…¶ä»–", "Other", "ğŸ“¦", 999)
        }

        categories = []
        for domain, tags in tag_categories.items():
            name_zh, name_en, icon, priority = meta.get(domain, (domain, domain.capitalize(), "ğŸ“", 100))
            categories.append(CategoryInfo(
                id=domain,
                name_zh=name_zh,
                name_en=name_en,
                description=f"{name_zh}ç›¸å…³çš„é¢„æµ‹å¸‚åœº",
                representative_tags=tags[:10],
                included_tags=set(tags),
                market_count=0, # å›ºå®šæ¨¡å¼ä¸ç»Ÿè®¡
                discovery_confidence=1.0,
                created_at=datetime.now(UTC).isoformat(),
                icon=icon,
                priority=priority
            ))

        return sorted(categories, key=lambda x: x.priority)

    def fetch_markets_for_category(
        self,
        category: CategoryInfo,
        limit: int = 500,
        force_refresh: bool = False
    ) -> List[Market]:
        """
        ä¸ºæŒ‡å®šç±»åˆ«è·å–å¸‚åœºæ•°æ®

        Args:
            category: ç±»åˆ«å¯¹è±¡
            limit: æœ€å¤§è·å–æ•°é‡
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

        Returns:
            å¸‚åœºåˆ—è¡¨
        """
        # å¦‚æœæ˜¯å›ºå®šåŸŸï¼Œå°è¯•ä½¿ç”¨ç°æœ‰çš„ç¼“å­˜æœºåˆ¶
        if not self.use_dynamic_categories:
            return self._fetch_domain_markets(category.id, force_refresh=force_refresh)

        # åŠ¨æ€åˆ†ç±»çš„å¸‚åœºè·å–ç­–ç•¥
        def fetcher():
            # ä¼˜å…ˆä½¿ç”¨ä»£è¡¨æ€§æ ‡ç­¾è·å–
            tag_slugs = category.representative_tags
            if not tag_slugs:
                # å¦‚æœæ²¡æœ‰ä»£è¡¨æ€§æ ‡ç­¾ï¼Œä½¿ç”¨å…¨éƒ¨æ ‡ç­¾çš„å‰20ä¸ªï¼ˆé¿å…è¯·æ±‚è¿‡å¤šï¼‰
                tag_slugs = sorted(list(category.included_tags))[:20]

            logging.info(f"[FETCH] æ­£åœ¨è·å–åŠ¨æ€åˆ†ç±» '{category.name_zh}' çš„å¸‚åœº (Tags: {len(tag_slugs)})")

            all_markets = []
            seen_ids = set()

            for i, slug in enumerate(tag_slugs):
                try:
                    markets = self.client.get_markets_by_tag_slug(
                        slug,
                        active=True,
                        limit=100,
                        min_liquidity=self.config.scan.min_liquidity
                    )
                    for m in markets:
                        if m.id not in seen_ids:
                            all_markets.append(m)
                            seen_ids.add(m.id)

                    if (i + 1) % 5 == 0:
                        logging.info(f"  è¿›åº¦: {i+1}/{len(tag_slugs)} tags, å·²è·å– {len(all_markets)} ä¸ªå¸‚åœº")
                except Exception as e:
                    logging.debug(f"  è·å– tag '{slug}' å¤±è´¥: {e}")
                    continue

            # æŒ‰æµåŠ¨æ€§æ’åºå¹¶æˆªæ–­
            all_markets.sort(key=lambda x: x.liquidity, reverse=True)
            return all_markets[:limit]

        # ä½¿ç”¨ç±»åˆ« ID ä½œä¸ºç¼“å­˜é”®
        cache_key = f"dynamic_cat_{category.id}"
        return self.market_cache.load_or_fetch(cache_key, fetcher, force_refresh)

    def _fetch_domain_markets(self, domain: str, subcategories: List[str] = None, force_refresh: bool = False) -> List[Market]:
        """
        è·å–æŒ‡å®šé¢†åŸŸçš„æ‰€æœ‰å¸‚åœºï¼ˆå¸¦ç¼“å­˜ï¼‰

        ä½¿ç”¨åˆ†ç±»åçš„tagsæ¥è·å–å¸‚åœºï¼Œç¡®ä¿è·å–è¯¥é¢†åŸŸçš„æ‰€æœ‰å¸‚åœºã€‚

        Args:
            domain: é¢†åŸŸæ ‡è¯† ("crypto", "politics", "sports", "economics", "entertainment", "other")
            subcategories: å­ç±»åˆ«ç­›é€‰ (å¦‚ ["bitcoin", "ethereum"])ï¼ŒNoneè¡¨ç¤ºè·å–å…¨éƒ¨
            force_refresh: å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°è·å–æ•°æ®

        Returns:
            å¸‚åœºåˆ—è¡¨
        """
        # åŠ è½½æ ‡ç­¾åˆ†ç±»
        tag_categories = self._load_tag_categories()

        if not tag_categories or domain not in tag_categories:
            logging.warning(f"[WARNING] åŸŸ '{domain}' çš„æ ‡ç­¾åˆ†ç±»ä¸å­˜åœ¨")
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            if domain == "crypto":
                fetcher = lambda: self.client.fetch_crypto_markets(
                    min_liquidity=self.config.scan.min_liquidity
                )
            else:
                def fetcher():
                    all_markets = self.client.get_markets(
                        limit=500,
                        min_liquidity=self.config.scan.min_liquidity
                    )
                    return [m for m in all_markets if self.domain_classifier.classify(m) == domain]
            return self.market_cache.load_or_fetch(domain, fetcher)

        # ä½¿ç”¨åˆ†ç±»åçš„tagsè·å–å¸‚åœº
        def fetcher():
            tag_slugs = tag_categories.get(domain, [])
            if not tag_slugs:
                logging.warning(f"[WARNING] åŸŸ '{domain}' æ²¡æœ‰å…³è”çš„tags")
                return []

            # ğŸ†• å­ç±»åˆ«ç­›é€‰å’Œæ‰©å±•ï¼ˆv2.1æ–°å¢ï¼‰
            if subcategories:
                all_tags = set(tag_slugs)
                expanded_tags = set()

                for subcat in subcategories:
                    # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æŸ¥æ‰¾ç›¸å…³æ ‡ç­¾
                    related = self._expand_subcategory(subcat, tag_slugs)
                    if related and related != [subcat]:
                        # æ‰¾åˆ°äº†ç›¸å…³æ ‡ç­¾ï¼Œæ·»åŠ åˆ°æ‰©å±•é›†åˆ
                        expanded_tags.update(related)
                    elif subcat in all_tags:
                        # ç²¾ç¡®åŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                        expanded_tags.add(subcat)
                    else:
                        logging.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…çš„æ ‡ç­¾: {subcat}")

                tag_slugs = list(expanded_tags)

                if not tag_slugs:
                    logging.warning(f"[WARNING] æ²¡æœ‰æœ‰æ•ˆçš„å­ç±»åˆ«")
                    return []

                subcat_info = f", å­ç±»åˆ«: {', '.join(sorted(set(subcategories)))}"
                logging.info(f"[FETCH] åŸŸ '{domain}'{subcat_info}")
                logging.info(f"[FETCH] æ‰©å±•ä¸º {len(tag_slugs)} ä¸ªtags: {', '.join(sorted(tag_slugs)[:5])}{'...' if len(tag_slugs) > 5 else ''}")
            else:
                logging.info(f"[FETCH] åŸŸ '{domain}' æœ‰ {len(tag_slugs)} ä¸ªtags")

            all_markets = []
            for i, slug in enumerate(tag_slugs):
                try:
                    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨å…¨é‡è·å–
                    max_results = (
                        self.config.scan.fetch_max_per_tag
                        if getattr(self.config.scan, 'enable_full_fetch', False)
                        else None
                    )
                    page_size = getattr(self.config.scan, 'fetch_page_size', 100)

                    markets = self.client.get_markets_by_tag_slug(
                        slug,
                        active=True,
                        limit=100,
                        min_liquidity=self.config.scan.min_liquidity,
                        max_results=max_results,
                        page_size=page_size
                    )
                    all_markets.extend(markets)
                    if (i + 1) % 20 == 0:
                        logging.info(f"  è¿›åº¦: {i+1}/{len(tag_slugs)} tags, å·²è·å– {len(all_markets)} ä¸ªå¸‚åœº")
                except Exception as e:
                    logging.debug(f"  è·å–tag '{slug}' å¤±è´¥: {e}")
                    continue

            # å»é‡ï¼ˆåŸºäºmarket IDï¼‰
            seen_ids = set()
            unique_markets = []
            for m in all_markets:
                if m.id not in seen_ids:
                    # ğŸ†• å¸‚åœºçŠ¶æ€å’Œåˆ°æœŸæ—¶é—´è¿‡æ»¤ (Phase 2)
                    if getattr(self.config.scan, 'exclude_resolved', True):
                        # å¦‚æœæ²¡æœ‰çŠ¶æ€å­—æ®µï¼Œæˆ‘ä»¬è‡³å°‘æ£€æŸ¥åˆ°æœŸæ—¶é—´
                        try:
                            if m.end_date:
                                end_dt = datetime.fromisoformat(m.end_date.replace('Z', '+00:00'))
                                now_dt = datetime.now(UTC)
                                hours_left = (end_dt - now_dt).total_seconds() / 3600
                                if hours_left < getattr(self.config.scan, 'min_hours_to_expiration', 1):
                                    continue
                        except Exception:
                            pass

                    seen_ids.add(m.id)
                    unique_markets.append(m)

            # ğŸ†• æ‰¹é‡è¡¥å……è®¢å•ç°¿æ•°æ® (Phase 1) - å¼‚æ­¥å¹¶å‘ç‰ˆ
            if getattr(self.config.scan, 'enable_orderbook', True):
                logging.info(f"[ORDERBOOK] æ­£åœ¨ä¸º {len(unique_markets)} ä¸ªå¸‚åœºå¹¶å‘è·å–å®æ—¶è®¢å•ç°¿æ•°æ®...")

                def fetch_task(market):
                    try:
                        # è·å– YES è®¢å•ç°¿
                        self.client.enrich_market_with_orderbook(market)
                        # è·å– NO è®¢å•ç°¿ (å¯¹å•è°ƒæ€§å¥—åˆ©è‡³å…³é‡è¦)
                        self.client.enrich_with_no_orderbook(market)
                        return True
                    except Exception as e:
                        logging.debug(f"è·å–è®¢å•ç°¿å¤±è´¥ {market.id}: {e}")
                        return False

                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œï¼ŒRateLimiter (çº¿ç¨‹å®‰å…¨) ä¼šæ§åˆ¶å®é™…è¯·æ±‚é¢‘ç‡
                max_workers = 5
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = {executor.submit(fetch_task, m): m for m in unique_markets}

                    completed = 0
                    for _ in as_completed(futures):
                        completed += 1
                        if completed % 50 == 0:
                            logging.info(f"  è¿›åº¦: {completed}/{len(unique_markets)} è®¢å•ç°¿å·²åŒæ­¥")

            logging.info(f"[DONE] åŸŸ '{domain}' è·å–åˆ° {len(unique_markets)} ä¸ªæœ‰æ•ˆå¸‚åœº")

            # ğŸ†• å¯åŠ¨ WebSocket å®æ—¶è®¢é˜… (Phase 8)
            token_ids = []
            for m in unique_markets:
                if m.token_id: token_ids.append(m.token_id)
                if m.no_token_id: token_ids.append(m.no_token_id)

            if token_ids:
                self.start_websocket(token_ids)

            return unique_markets

        # ğŸ†• æ„å»ºç¼“å­˜é”®ï¼šdomain + subcategoriesï¼ˆv2.1æ–°å¢ï¼‰
        cache_key = domain
        if subcategories:
            # å°†subcategoriesæ’åºååŠ å…¥ç¼“å­˜é”®ï¼Œç¡®ä¿é¡ºåºä¸å½±å“ç¼“å­˜
            subcat_suffix = "_".join(sorted(subcategories))
            cache_key = f"{domain}_{subcat_suffix}"

        return self.market_cache.load_or_fetch(cache_key, fetcher, force_refresh)


    def _generate_polymarket_links(self, markets: List[Dict]) -> List[str]:
        """
        ç”Ÿæˆ Polymarket å¸‚åœºé“¾æ¥

        Args:
            markets: å¸‚åœºåˆ—è¡¨ï¼ˆä» ArbitrageOpportunity.markets è·å–ï¼‰

        Returns:
            é“¾æ¥åˆ—è¡¨
        """
        links = []
        for market in markets:
            # Polymarket URL æ ¼å¼
            # https://polymarket.com/event/{event_slug}?market={market_id}
            market_id = market.get('id', '')
            # ä½¿ç”¨ event_id æˆ–ç®€å•çš„å¸‚åœº ID
            url = f"https://polymarket.com/event/market?market={market_id}"
            links.append(url)

        return links

    def _save_report(
        self,
        opportunities: List[ArbitrageOpportunity],
        domain: str = "default"
    ):
        """
        ä¿å­˜æŠ¥å‘Š

        Args:
            opportunities: å¥—åˆ©æœºä¼šåˆ—è¡¨
            domain: å¸‚åœºé¢†åŸŸï¼ˆç”¨äºæ–‡ä»¶åï¼‰
        """
        os.makedirs(self.config.output.output_dir, exist_ok=True)

        output_file = os.path.join(
            self.config.output.output_dir,
            f"scan_{domain}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )

        report = {
            "scan_time": datetime.now().isoformat(),
            "domain": domain,
            "config": {
                "llm_provider": self.config.llm.provider,
                "min_profit_pct": self.config.scan.min_profit_pct,
                "min_liquidity": self.config.scan.min_liquidity,
                "min_confidence": self.config.scan.min_confidence
            },
            "opportunities_count": len(opportunities),
            "opportunities": [json_serialize(opp) for opp in opportunities]
        }

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logging.info(f"[OK] æŠ¥å‘Šå·²ä¿å­˜åˆ° {output_file}")
        print(f"      [OK] æŠ¥å‘Šå·²ä¿å­˜åˆ° {output_file}")

    def _analyze_cluster_fully(self, cluster: List[Market]) -> List[ArbitrageOpportunity]:
        """
        [Phase 5.2] æ‰¹é‡åˆ†æè¯­ä¹‰èšç±»ç°‡å¹¶æå–æœºä¼š
        """
        if len(cluster) < 2:
            return []

        cluster_id = f"cluster_{cluster[0].id[:8]}"
        results = self.analyzer.analyze_cluster(cluster_id, cluster)

        valid_opportunities = []
        market_map = {m.id: m for m in cluster}

        # 1. å¤„ç†ç‚¹å¯¹ç‚¹å…³ç³» (è•´å«ã€ç­‰ä»·ã€äº’æ–¥)
        for rel in results.get("relationships", []):
            m_a = market_map.get(rel.get("market_a_id"))
            m_b = market_map.get(rel.get("market_b_id"))

            if not m_a or not m_b:
                continue

            # æ„é€ åŸºç¡€æœºä¼šå¯¹è±¡
            relationship = rel.get("relationship", "unknown")
            tmp_opp = {
                "id": f"batch_{m_a.id}_{m_b.id}",
                "type": f"BATCH_{relationship}",
                "relationship": relationship,
                "markets": [
                    {"question": m_a.question, "id": m_a.id, "yes_price": m_a.yes_price},
                    {"question": m_b.question, "id": m_b.id, "yes_price": m_b.yes_price}
                ],
                "confidence": rel.get("confidence", 0.8),
                "reasoning": rel.get("reasoning", ""),
                "action": "æ‰§è¡Œå¥—åˆ©",
                "edge_cases": [],
                "needs_review": ["æ‰¹é‡åˆ†æè¯†åˆ«", "è¯·äººå·¥æ ¸å®é€»è¾‘"]
            }

            # è°ƒç”¨å·²æœ‰çš„æ·±åº¦éªŒè¯æµç¨‹
            # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ª ArbitrageOpportunity å¯¹è±¡ç»“æ„
            class SimpleNamespace:
                def __init__(self, **kwargs):
                    self.__dict__.update(kwargs)

            validated_opp = self._validate_and_enrich_opportunity(SimpleNamespace(**tmp_opp), cluster)
            if validated_opp:
                valid_opportunities.append(validated_opp)

        # 2. å¤„ç†ç»„åˆ/åˆæˆæœºä¼š (å®Œå¤‡é›†ç­‰)
        for sync_opp in results.get("synthetic_opportunities", []):
            involved_ids = sync_opp.get("market_ids", [])
            involved_markets = [market_map[mid] for mid in involved_ids if mid in market_map]

            if len(involved_markets) < 2:
                continue

            # ç‰¹æ®Šå¤„ç†å®Œå¤‡é›†
            if sync_opp.get("type") == "EXHAUSTIVE_SET":
                from datetime import datetime
                # ä½¿ç”¨ MathValidator éªŒè¯å®Œå¤‡é›†
                math_report = self.validation_engine.math_validator.validate_exhaustive_set(
                    [MarketData(id=m.id, question=m.question, yes_price=m.yes_price, no_price=m.no_price,
                                liquidity=m.liquidity, end_date=m.end_date, best_ask=m.best_ask)
                     for m in involved_markets]
                )

                if math_report.is_valid():
                    final_opp = ArbitrageOpportunity(
                        id=f"sync_{datetime.now().strftime('%H%M%S')}",
                        type="BATCH_EXHAUSTIVE_SET",
                        relationship="exhaustive",
                        markets=[{"question": m.question, "id": m.id, "yes_price": m.yes_price} for m in involved_markets],
                        confidence=0.9,
                        total_cost=math_report.total_cost,
                        guaranteed_return=1.0,
                        profit=math_report.expected_profit,
                        profit_pct=math_report.profit_pct,
                        action=sync_opp.get("action", "ä¹°å…¥å…¨é›†"),
                        reasoning=sync_opp.get("logic", ""),
                        edge_cases=[],
                        needs_review=["éªŒè¯å®Œå¤‡æ€§", "æ£€æŸ¥ç»“ç®—è§„åˆ™"],
                        timestamp=datetime.now().isoformat(),
                        apy=self.validation_engine.apy_calculator.calculate_apy(
                            math_report.profit_pct,
                            self.validation_engine.apy_calculator.calculate_days_to_resolution(involved_markets[0].end_date)
                        )
                    )
                    valid_opportunities.append(final_opp)

        return valid_opportunities

    def _validate_and_enrich_opportunity(self, opp: Any, markets: List[Market]) -> Optional[ArbitrageOpportunity]:
        """
        ä½¿ç”¨ ValidationEngine å¯¹å‘ç°çš„æœºä¼šæ‰§è¡Œæ·±åº¦éªŒè¯å¹¶è¡¥å……å­—æ®µ
        æ”¯æŒ MonotonicityViolation å’Œæ ‡å‡†çš„ ArbitrageOpportunity
        """
        try:
            involved_markets = []
            relationship = "unknown"

            # 1. è¯†åˆ«å¹¶æå–æ¶‰åŠçš„å¸‚åœºå¯¹è±¡ (Phase 4 å…¼å®¹æ€§å¢å¼º)
            if hasattr(opp, 'low_market') and hasattr(opp, 'high_market'):
                # å¤„ç†å•è°ƒæ€§ç­–ç•¥çš„ MonotonicityViolation å¯¹è±¡
                involved_markets = [opp.low_market.market, opp.high_market.market]
                if getattr(opp, 'violation_type', '') == "temporal":
                    relationship = "IMPLIES_AB"
                else:
                    dir_val = opp.direction.value if hasattr(opp.direction, 'value') else str(opp.direction)
                    relationship = "IMPLIES_BA" if dir_val == "above" else "IMPLIES_AB"
            elif hasattr(opp, 'markets') and isinstance(opp.markets, list):
                # å¤„ç†å·²åŒ…è£…å¥½çš„æœºä¼šå¯¹è±¡
                involved_questions = [m.get('question', '') if isinstance(m, dict) else getattr(m, 'question', '') for m in opp.markets]
                involved_markets = [m for m in markets if m.question in involved_questions]
                relationship = getattr(opp, 'relationship', 'unknown')

            if len(involved_markets) < 2:
                return opp if isinstance(opp, ArbitrageOpportunity) else None

            # ğŸ†• [Phase 8] æ³¨å…¥ WebSocket å®æ—¶ä»·æ ¼
            # åœ¨éªŒè¯å‰ï¼Œä¼˜å…ˆä½¿ç”¨ WS ç¼“å­˜ä¸­çš„ç›˜å£æ•°æ®è¦†ç›–æ—§çš„ REST API æ•°æ®
            for m in involved_markets:
                if m.token_id:
                    ws_price = self.ws_client.cache.get_price(m.token_id)
                    if ws_price:
                        m.best_bid = ws_price["best_bid"]
                        m.best_ask = ws_price["best_ask"]
                if m.no_token_id:
                    ws_price_no = self.ws_client.cache.get_price(m.no_token_id)
                    if ws_price_no:
                        m.best_bid_no = ws_price_no["best_bid"]
                        m.best_ask_no = ws_price_no["best_ask"]

            # 2. æ‰§è¡Œäº”å±‚éªŒè¯ (Layer 2-4)
            target_size = getattr(self.config.scan, 'target_size_usd', 500.0)
            v_result = self.validation_engine.validate_all_layers(
                involved_markets,
                relationship,
                target_size_usd=target_size
            )

            # å¦‚æœæ·±åº¦éªŒè¯æœªé€šè¿‡ï¼Œè¿‡æ»¤æ‰è¯¥æœºä¼š
            if not v_result["passed"]:
                logging.info(f"[REJECTED] {v_result['rejection_layer']}: {v_result['reason']}")
                return None

            # 3. æ„é€ æˆ–æ›´æ–°æ ‡å‡† ArbitrageOpportunity å¯¹è±¡ (Phase 4 æ ¸å¿ƒè½¬æ¢)
            if not isinstance(opp, ArbitrageOpportunity):
                # ä»è¿èƒŒå¯¹è±¡è½¬æ¢ä¸ºæ ‡å‡†æœºä¼šæ ¼å¼ï¼ŒåŒ…å«æ‰§è¡Œå¼•æ“éœ€è¦çš„ token_id
                opp = ArbitrageOpportunity(
                    id=getattr(opp, 'id', f"opp_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"),
                    type=getattr(opp, 'type', 'MONOTONICITY_VIOLATION'),
                    relationship=relationship,
                    markets=[{
                        "question": m.question,
                        "id": m.id,
                        "yes_price": m.yes_price,
                        "token_id": getattr(m, 'token_id', ''),
                        "no_token_id": getattr(m, 'no_token_id', '')
                    } for m in involved_markets],
                    confidence=getattr(opp, 'confidence', 1.0),
                    total_cost=v_result["metrics"].get("total_cost", 0.0),
                    guaranteed_return=1.0,
                    profit=v_result["metrics"].get("expected_profit", 0.0),
                    profit_pct=v_result["metrics"].get("profit_pct", 0.0),
                    action=getattr(opp, 'action', "æ‰§è¡Œå¯¹å†²å¥—åˆ©"),
                    reasoning=getattr(opp, 'reasoning', v_result["reason"]),
                    edge_cases=getattr(opp, 'edge_cases', []),
                    needs_review=getattr(opp, 'needs_review', ["éªŒè¯é€»è¾‘å…³ç³»", "æ£€æŸ¥ç»“ç®—è§„åˆ™"]),
                    timestamp=datetime.now().isoformat()
                )

            # 4. å¡«å…… 11 ä¸ªé£æ§å­—æ®µ (Phase 2.5)
            metrics = v_result.get("metrics", {})
            opp.oracle_alignment = metrics.get("oracle_alignment", "UNKNOWN")
            opp.days_to_resolution = metrics.get("days_to_resolution", 0)
            opp.apy = metrics.get("apy", 0.0)
            opp.apy_rating = metrics.get("apy_rating", "N/A")

            # åˆ©æ¶¦ä¸æ»‘ç‚¹åº¦é‡
            opp.mid_price_profit = getattr(opp, 'profit', 0.0)
            opp.effective_profit = metrics.get("expected_profit", 0.0)
            opp.slippage_cost = metrics.get("slippage_estimate", 0.0) * target_size / 100

            # èµ„é‡‘å®¹é‡ä¸ Gas ä¼°ç®—
            liquidity_list = [m.liquidity for m in involved_markets if hasattr(m, 'liquidity')]
            opp.max_position_usd = min(liquidity_list) * 0.1 if liquidity_list else 0.0
            opp.gas_estimate = 0.5  # é¢„ä¼° Polygon é“¾æ‰§è¡Œæˆæœ¬

            opp.validation_results = v_result

            # 5. ç”Ÿæˆå¤æ ¸æ¸…å• (Layer 5)
            checklist_content = self.validation_engine.generate_human_checklist(opp)
            checklist_dir = Path(self.config.output.output_dir) / "checklists"
            checklist_dir.mkdir(parents=True, exist_ok=True)
            checklist_path = checklist_dir / f"checklist_{opp.id}.md"

            with open(checklist_path, "w", encoding="utf-8") as f:
                f.write(checklist_content)

            opp.checklist_path = str(checklist_path)
            logging.info(f"[VALIDATED] æœºä¼š {opp.id} é€šè¿‡æ·±åº¦éªŒè¯ï¼ŒAPY: {opp.apy:.1f}%")

            # âœ… è§¦å‘å®æ—¶æ¨é€ (Phase 3.3)
            if hasattr(self, 'notifier'):
                self.notifier.send_notification(opp)

            return opp
        except Exception as e:
            logging.error(f"éªŒè¯æœºä¼šæ—¶å‡ºé”™: {e}")
            traceback.print_exc()
            return opp if isinstance(opp, ArbitrageOpportunity) else None

    def sync_settlements(self):
        """
        [Phase 4.8] åŒæ­¥å·²å®Œæˆäº¤æ˜“çš„ç»“ç®—çŠ¶æ€å¹¶è®¡ç®—å®é™… PnL
        """
        print("\n" + "=" * 65)
        print("[SETTLEMENT] æ­£åœ¨åŒæ­¥äº¤æ˜“ç»“ç®—çŠ¶æ€...")
        print("=" * 65)

        pending = self.recorder.get_pending_settlements()
        if not pending:
            print("  æš‚æ— å¾…ç»“ç®—çš„äº¤æ˜“è®°å½•ã€‚")
            return

        print(f"  å‘ç° {len(pending)} æ¡å¾…å¤„ç†è®°å½•ã€‚")

        updated_count = 0
        for exec_rec in pending:
            exec_id = exec_rec['exec_id']
            opp_id = exec_rec['opp_id']
            details = json.loads(exec_rec['details_json'] or '{}')
            instructions = details.get('instructions', [])

            if not instructions:
                continue

            all_resolved = True
            total_return = 0.0
            results_summary = []

            print(f"\n  æ£€æŸ¥æ‰§è¡Œ ID: {exec_id[:8]}... (æœºä¼š: {opp_id})")

            for inst in instructions:
                market_id = inst.get('market_id') or inst.get('id') # å…¼å®¹ä¸åŒæ ¼å¼
                if not market_id:
                    # å°è¯•ä»é—®é¢˜æè¿°åæŸ¥ (ä¿åº•)
                    continue

                market_data = self.client.get_market_details(market_id)
                if not market_data:
                    all_resolved = False
                    break

                # æ£€æŸ¥å¸‚åœºæ˜¯å¦å·²ç»“ç®—
                # Polymarket API: status="closed" æˆ– "resolved"
                status = market_data.get('status', '').lower()
                if status not in ['closed', 'resolved']:
                    all_resolved = False
                    print(f"    - å¸‚åœºå°šæœªç»“ç®—: {inst.get('market')[:40]}...")
                    break

                # è·å–ä¸­å¥–ç»“æœ
                winning_outcome = market_data.get('winningOutcome')
                if winning_outcome is None:
                    all_resolved = False
                    print(f"    - å¸‚åœºå·²å…³é—­ä½†å°šæœªå…¬å¸ƒç»“æœ: {inst.get('market')[:40]}...")
                    break

                # è®¡ç®—è¯¥ç¬”è®¢å•çš„æ”¶ç›Š
                # æˆ‘ä»¬å‡è®¾ç›®å‰åªå¤„ç† YES åˆçº¦ä¹°å…¥ (instructions ä¸­ token="YES")
                is_win = False
                if inst.get('token') == "YES" and winning_outcome == "0": # 0 é€šå¸¸æ˜¯ YES
                    is_win = True
                elif inst.get('token') == "NO" and winning_outcome == "1": # 1 é€šå¸¸æ˜¯ NO
                    is_win = True

                leg_return = 1.0 if is_win else 0.0
                total_return += leg_return
                results_summary.append({
                    "market": inst.get('market'),
                    "outcome": winning_outcome,
                    "is_win": is_win,
                    "return": leg_return
                })
                print(f"    - {'[WIN]' if is_win else '[LOSS]'} {inst.get('market')[:40]}...")

            if all_resolved:
                # è®¡ç®— realized PnL
                # PnL = Total Return - Total Cost
                # æ³¨æ„: total_cost_usd åœ¨æ•°æ®åº“ä¸­å­˜çš„æ˜¯ç»„åˆæ€»æˆæœ¬
                realized_pnl = total_return - exec_rec['total_cost_usd']

                # æ›´æ–°æ•°æ®åº“
                self.recorder.update_execution(exec_id, "SETTLED", {
                    "settlement_details": results_summary,
                    "total_return": total_return,
                    "realized_pnl": realized_pnl,
                    "settled_at": datetime.now(timezone.utc).isoformat()
                })

                # åŒæ—¶æ›´æ–° realizes_pnl ä¸“ç”¨å­—æ®µ
                try:
                    with sqlite3.connect(self.recorder.db_path) as conn:
                        conn.execute(
                            "UPDATE execution_history SET realized_pnl = ?, settled_at = ? WHERE exec_id = ?",
                            (realized_pnl, datetime.now(timezone.utc).isoformat(), exec_id)
                        )
                except Exception as e:
                    logging.error(f"æ›´æ–°ç»“ç®—å­—æ®µå¤±è´¥: {e}")

                print(f"  [OK] ç»“ç®—å®Œæˆ! PnL: ${realized_pnl:.4f} USD")
                updated_count += 1

        print(f"\n  åŒæ­¥ç»“æŸï¼Œå·²æ›´æ–° {updated_count} æ¡è®°å½•ã€‚")
        print("=" * 65 + "\n")

    def _on_opportunity_found(
        self,
        opp: ArbitrageOpportunity,
        opportunities: List[ArbitrageOpportunity]
    ) -> bool:
        """å¤„ç†å‘ç°çš„å¥—åˆ©æœºä¼š

        ç»Ÿä¸€å¤„ç†æœºä¼šå‘ç°æ—¶çš„é€»è¾‘ï¼š
        - DEBUG æ¨¡å¼ï¼šæš‚åœç­‰å¾…ç”¨æˆ·ç¡®è®¤
        - PRODUCTION æ¨¡å¼ï¼šè‡ªåŠ¨æ”¶é›†æ‰€æœ‰æœºä¼š

        Args:
            opp: å‘ç°çš„å¥—åˆ©æœºä¼š
            opportunities: æœºä¼šåˆ—è¡¨ï¼ˆç”¨äºæœ€ç»ˆæŠ¥å‘Šï¼‰

        Returns:
            True if scanning should continue, False to exit
        """
        # å§‹ç»ˆæ”¶é›†åˆ° discovered_opportunitiesï¼ˆç”¨äºè‡ªåŠ¨ä¿å­˜ï¼‰
        self.discovered_opportunities.append(opp)

        if self.run_mode == RunMode.DEBUG:
            # DEBUG æ¨¡å¼ï¼šæš‚åœç¡®è®¤
            return self._handle_opportunity_verification(opp, opportunities)
        else:
            # PRODUCTION æ¨¡å¼ï¼šè‡ªåŠ¨æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            opportunities.append(opp)
            return True

    def _print_summary(self, opportunities: List[ArbitrageOpportunity]):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 65)
        print("æ‰«æç»“æœæ‘˜è¦")
        print("=" * 65)

        if not opportunities:
            print("\næš‚æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å¥—åˆ©æœºä¼š")
            print("è¿™å¾ˆæ­£å¸¸â€”â€”å¥½æœºä¼šä¸æ˜¯æ—¶æ—¶éƒ½æœ‰\n")
            return

        print(f"\n[RESULT] å‘ç° {len(opportunities)} ä¸ªæ½œåœ¨å¥—åˆ©æœºä¼š:\n")

        for i, opp in enumerate(opportunities, 1):
            print(f"{'â”€' * 60}")
            print(f"æœºä¼š #{i}: {opp.type}")
            print(f"{'â”€' * 60}")

            # ğŸ”¥ æ˜¾ç¤ºæ ¸å¿ƒé£æ§åº¦é‡ (Phase 2.5/3.5 å¢å¼º)
            apy_val = getattr(opp, 'apy', 0.0)
            rating = getattr(opp, 'apy_rating', 'N/A')
            apy_str = f"{apy_val:.1f}% ({rating})"

            print(f"ğŸ”¥ å¹´åŒ–æ”¶ç›Š (APY): {apy_str:25} ğŸ¯ ç½®ä¿¡åº¦: {opp.confidence:.0%}")
            print(f"ğŸ’° é¢„æœŸå‡€åˆ©æ¶¦: {opp.profit_pct:.2f}% ({opp.profit:.4f} USD)   â³ é¢„ä¼°é”ä»“: {getattr(opp, 'days_to_resolution', 0)} å¤©")
            print(f"ğŸ“¡ é¢„è¨€æœºå¯¹é½: {getattr(opp, 'oracle_alignment', 'UNKNOWN'):25} ğŸ›¡ï¸ æ»‘ç‚¹æŸå¤±: {getattr(opp, 'slippage_cost', 0):.4f} USD")
            print(f"ğŸ“ˆ å»ºè®®æœ€å¤§ä»“ä½: ${getattr(opp, 'max_position_usd', 0):,.0f} USD")
            print(f"\næ“ä½œ:")
            for line in opp.action.split('\n'):
                print(f"  {line}")

            # âœ… æ–°å¢ï¼šPolymarket é“¾æ¥
            links = self._generate_polymarket_links(opp.markets)
            print(f"\n[Polymarket é“¾æ¥:]")
            for j, (market, link) in enumerate(zip(opp.markets, links), 1):
                question = market.get('question', '')[:60]
                print(f"  {j}. {question}...")
                print(f"     {link}")

            # âœ… æ–°å¢ï¼šäººå·¥éªŒè¯æ¸…å•
            print(f"\n[WARNING] äººå·¥éªŒè¯æ¸…å•:")
            print(f"  [ ] éªŒè¯é€»è¾‘å…³ç³»æ˜¯å¦æ­£ç¡®: {opp.type}")
            print(f"  [ ] æ£€æŸ¥ç»“ç®—è§„åˆ™æ˜¯å¦å…¼å®¹")

            # å¦‚æœæœ‰ä¸¤ä¸ªå¸‚åœºï¼Œæ˜¾ç¤ºç»“ç®—æ—¶é—´å¯¹æ¯”
            if len(opp.markets) >= 2:
                market_1 = opp.markets[0]
                market_2 = opp.markets[1]
                print(f"  [ ] åœ¨ Polymarket ä¸Šç¡®è®¤å½“å‰ä»·æ ¼")
                print(f"  [ ] æ£€æŸ¥æµåŠ¨æ€§: ${market_1.get('yes_price', 0):.2f} vs ${market_2.get('yes_price', 0):.2f}")
            print(f"  [ ] æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šè§„åˆ™ï¼ˆå¦‚æå‰ç»“ç®—ï¼‰")
            print(f"  [ ] éªŒè¯ LLM åˆ†æçš„åˆç†æ€§")

            # åŸæœ‰çš„ needs_review å†…å®¹
            if opp.needs_review:
                print(f"\n[NOTE] é¢å¤–æ³¨æ„äº‹é¡¹:")
                for item in opp.needs_review:
                    print(f"  â€¢ {item}")

            print()

    # ============================================================
    # ğŸ†• éªŒè¯æ¨¡å¼ç›¸å…³æ–¹æ³•
    # ============================================================

    def _print_opportunity_detailed(self, opp: ArbitrageOpportunity) -> None:
        """
        æ‰“å°å¥—åˆ©æœºä¼šçš„å®Œæ•´è¯¦ç»†ä¿¡æ¯ï¼ˆéªŒè¯æ¨¡å¼ï¼‰

        Args:
            opp: å¥—åˆ©æœºä¼šå¯¹è±¡
        """
        self.opportunity_counter += 1

        print("\n" + "=" * 60)
        print(f"[å¥—åˆ©æœºä¼š #{self.opportunity_counter}] {opp.type}")
        print("=" * 60)

        # ã€å¸‚åœºä¿¡æ¯ã€‘
        print("\n[å¸‚åœºä¿¡æ¯]")
        print("-" * 60)
        links = self._generate_polymarket_links(opp.markets)

        for i, (market, link) in enumerate(zip(opp.markets, links), 1):
            role = f"å¸‚åœº {chr(64+i)}"  # A, B, C...
            print(f"{role}:")
            print(f"  é—®é¢˜: {market.get('question', '')}")
            print(f"  YESä»·æ ¼: ${market.get('yes_price', 0):.4f} (ask: ${market.get('best_ask', 0):.4f})")
            print(f"  NOä»·æ ¼:  ${market.get('no_price', 0):.4f} (bid: ${market.get('best_bid', 0):.4f})")
            print(f"  æµåŠ¨æ€§:  ${market.get('liquidity', 0):,.0f} USDC")
            end_date = market.get('end_date', 'N/A')
            if end_date and end_date != 'N/A':
                end_date = end_date[:10] if 'T' in end_date else end_date
            print(f"  ç»“ç®—:   {end_date}")
            print(f"  é“¾æ¥:   {link}")
            print()

        # ã€å¥—åˆ©è¯¦æƒ…ã€‘
        print("[å¥—åˆ©è¯¦æƒ…]")
        print("-" * 60)
        print(f"é€»è¾‘å…³ç³»: {opp.relationship}")
        print(f"ç½®ä¿¡åº¦:   {opp.confidence:.0%}")
        print(f"åˆ©æ¶¦ç‡:   {opp.profit_pct:.2f}%")
        print(f"\næ“ä½œ:")
        for line in opp.action.split('\n'):
            print(f"  {line}")

        # ã€LLM å®Œæ•´æ¨ç†ã€‘
        if opp.reasoning:
            print("\n[LLM å®Œæ•´æ¨ç†]")
            print("-" * 60)
            # é™åˆ¶æ¨ç†é•¿åº¦ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
            reasoning = opp.reasoning
            if len(reasoning) > 2000:
                reasoning = reasoning[:2000] + "\n... (æ¨ç†å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
            print(reasoning)

        # ã€é£é™©æç¤ºã€‘
        print("\n[é£é™©æç¤º]")
        print("-" * 60)
        for item in opp.needs_review:
            print(f"  - {item}")

        if opp.edge_cases:
            print("\nEdge Cases:")
            for case in opp.edge_cases:
                print(f"  - {case}")

        print("=" * 60)

    def _handle_opportunity_verification(
        self,
        opp: ArbitrageOpportunity,
        opportunities: List[ArbitrageOpportunity]
    ) -> bool:
        """
        å¤„ç†å¥—åˆ©æœºä¼šçš„éªŒè¯æµç¨‹ï¼ˆäº¤äº’å¼ï¼‰

        Args:
            opp: å‘ç°çš„å¥—åˆ©æœºä¼š
            opportunities: æœºä¼šåˆ—è¡¨ï¼ˆç”¨äºä¿å­˜ï¼‰

        Returns:
            True if scanning should continue, False to exit
        """
        # æ³¨æ„ï¼šæœºä¼šå·²åœ¨ _on_opportunity_found ä¸­æ·»åŠ åˆ° discovered_opportunities

        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        self._print_opportunity_detailed(opp)

        while True:
            try:
                choice = input(
                    "\n[éªŒè¯æ¨¡å¼] æ“ä½œ (Enter=ç»§ç»­,s=ä¿å­˜,e=æ‰§è¡Œ(MOCK),f=è¯¯æŠ¥,q=é€€å‡º,d=è¯¦æƒ…,r=é˜ˆå€¼,l=æµåŠ¨æ€§,j=å­˜æ–‡ä»¶,?=å¸®åŠ©): "
                ).strip().lower()

                if not choice or choice == 'enter':
                    print("  -> è·³è¿‡æ­¤æœºä¼šï¼Œç»§ç»­æ‰«æ...")
                    return True

                elif choice == 's':
                    opportunities.append(opp)
                    print("  -> å·²ä¿å­˜åˆ°ç»“æœåˆ—è¡¨ï¼Œç»§ç»­æ‰«æ...")
                    return True

                elif choice == 'e':
                    # âœ… æ‰§è¡Œ Layer 6 ç»ˆæéªŒè¯ä¸æ¨¡æ‹Ÿæ‰§è¡Œ (Phase 4)
                    check = self.execution_engine.pre_flight_check(opp)
                    if check["can_execute"]:
                        print(f"  [OK] Layer 6 éªŒè¯é€šè¿‡: {check['reason']}")
                        log_path = self.execution_engine.execute_mock(opp, check["instructions"])
                        print(f"  ğŸš€ æ¨¡æ‹Ÿæ‰§è¡ŒæˆåŠŸ! æ—¥å¿—: {log_path}")
                    else:
                        print(f"  [REJECTED] Layer 6 éªŒè¯å¤±è´¥: {check['reason']}")
                    continue

                elif choice == 'f':
                    reason = input("  -> è¯·è¾“å…¥è¯¯æŠ¥åŸå› : ").strip()
                    self.false_positive_log.append({
                        'opportunity': json_serialize(opp),
                        'reason': reason,
                        'timestamp': datetime.now().isoformat()
                    })
                    print("  -> å·²è®°å½•ä¸ºè¯¯æŠ¥ï¼Œç»§ç»­æ‰«æ...")
                    return True

                elif choice == 'q':
                    print("  -> é€€å‡ºæ‰«æ...")
                    return False

                elif choice == 'd':
                    # æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
                    print("\n[è°ƒè¯•è¯¦æƒ…]")
                    print(f"  ID: {opp.id}")
                    print(f"  æ€»æˆæœ¬: ${opp.total_cost:.4f}")
                    print(f"  ä¿è¯å›æŠ¥: ${opp.guaranteed_return:.4f}")
                    print(f"  æ—¶é—´æˆ³: {opp.timestamp}")
                    if opp.edge_cases:
                        print(f"  è¾¹ç•Œæƒ…å†µ: {opp.edge_cases}")
                    continue

                elif choice == 'r':
                    new_threshold = input(f"  -> å½“å‰åˆ©æ¶¦ç‡é˜ˆå€¼={self.config.scan.min_profit_pct:.1%}ï¼Œæ–°é˜ˆå€¼: ").strip()
                    try:
                        self.config.scan.min_profit_pct = float(new_threshold)
                        print(f"  -> é˜ˆå€¼å·²æ›´æ–°ä¸º {self.config.scan.min_profit_pct:.1%}")
                    except ValueError:
                        print("  -> æ— æ•ˆè¾“å…¥")
                    continue

                elif choice == 'l':
                    new_liquidity = input(f"  -> å½“å‰æœ€å°æµåŠ¨æ€§=${self.config.scan.min_liquidity:,.0f}ï¼Œæ–°å€¼: ").strip()
                    try:
                        self.config.scan.min_liquidity = float(new_liquidity)
                        print(f"  -> æµåŠ¨æ€§é˜ˆå€¼å·²æ›´æ–°ä¸º ${self.config.scan.min_liquidity:,.0f}")
                    except ValueError:
                        print("  -> æ— æ•ˆè¾“å…¥")
                    continue

                elif choice == 'j':
                    filename = f"opportunity_{opp.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    filepath = Path(self.config.output.output_dir) / filename
                    filepath.parent.mkdir(parents=True, exist_ok=True)
                    with open(filepath, 'w', encoding='utf-8') as f:
                        json.dump(json_serialize(opp), f, indent=2, ensure_ascii=False)
                    print(f"  -> å·²ä¿å­˜åˆ° {filepath}")
                    continue

                elif choice == '?':
                    print("\n[å‘½ä»¤å¸®åŠ©]")
                    print("  Enter - ç»§ç»­æ‰«æï¼ˆä¸ä¿å­˜æ­¤æœºä¼šï¼‰")
                    print("  s    - ä¿å­˜æ­¤æœºä¼šåˆ°ç»“æœåˆ—è¡¨")
                    print("  f    - æ ‡è®°ä¸ºè¯¯æŠ¥å¹¶è®°å½•åŸå› ")
                    print("  q    - é€€å‡ºæ‰«æ")
                    print("  d    - æ˜¾ç¤ºæ›´å¤šè°ƒè¯•è¯¦æƒ…")
                    print("  r    - è°ƒæ•´æœ€å°åˆ©æ¶¦ç‡é˜ˆå€¼")
                    print("  l    - è°ƒæ•´æœ€å°æµåŠ¨æ€§é˜ˆå€¼")
                    print("  j    - ä¿å­˜æ­¤æœºä¼šåˆ°å•ç‹¬JSONæ–‡ä»¶")
                    print("  ?    - æ˜¾ç¤ºæ­¤å¸®åŠ©")
                    continue

                else:
                    print("  -> æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ ? æŸ¥çœ‹å¸®åŠ©")
                    continue

            except KeyboardInterrupt:
                print("\n  -> æ£€æµ‹åˆ° Ctrl+Cï¼Œé€€å‡ºæ‰«æ...")
                return False
            except EOFError:
                print("\n  -> æ£€æµ‹åˆ° EOFï¼Œé€€å‡ºæ‰«æ...")
                return False

    def _show_execution_stats(self):
        """
        [Phase 4.6/4.7/4.8] æ˜¾ç¤ºäº¤æ˜“æ‰§è¡Œç»Ÿè®¡å’Œ PnL æ•°æ®
        """
        stats = self.recorder.get_execution_stats()

        print("\n" + "=" * 65)
        print("[STATS] äº¤æ˜“æ‰§è¡Œä¸æ”¶ç›Šç»Ÿè®¡ (PnL Dashboard)")
        print("=" * 65)

        if stats["total_count"] == 0:
            print("\næš‚æ— å†å²æ‰§è¡Œè®°å½•ã€‚")
            return

        # 1. è§„æ¨¡ç»Ÿè®¡
        print(f"\n[è§„æ¨¡ç»Ÿè®¡]")
        print(f"  æ€»æ‰§è¡Œå°è¯•: {stats['total_count']} (MOCK: {stats['mock_count']}, REAL: {stats['real_count']})")
        print(f"  Layer 6 æ‹¦æˆª: {stats['rejected_l6_count']} (ä»·æ ¼å˜åŠ¨å¯¼è‡´æ‹’ç»)")
        print(f"  å·²ç»“ç®—äº¤æ˜“: {stats['settled_count']}")

        success_color = "\033[92m" if stats['success_rate'] > 80 else "\033[93m"
        reset_color = "\033[0m"
        print(f"  æ‰§è¡ŒæˆåŠŸç‡: {success_color}{stats['success_rate']:.1f}%{reset_color} (ä¸å« L6 æ‹¦æˆª)")

        # 2. æ”¶ç›Šç»Ÿè®¡
        print(f"\n[æ”¶ç›Šç»Ÿè®¡]")
        print(f"  ç´¯è®¡æŠ•å…¥æœ¬é‡‘: ${stats['total_cost_usd']:.2f} USD")
        print(f"  é¢„æœŸæ€»åˆ©æ¶¦:   ${stats['total_expected_profit_usd']:.2f} USD")

        pnl_color = "\033[92m" if stats['realized_pnl_usd'] > 0 else ("\033[91m" if stats['realized_pnl_usd'] < 0 else "")
        print(f"\n  å·²å®ç°å‡€æŸç›Š (Realized): {pnl_color}${stats['realized_pnl_usd']:.4f} USD{reset_color}")

        pending_color = "\033[94m" # Blue for pending
        print(f"  å¾…ç»“ç®—é¢„ä¼° (Pending):  {pending_color}${stats['pending_pnl_usd']:.4f} USD{reset_color}")

        if stats['total_cost_usd'] > 0:
            total_pnl = stats['realized_pnl_usd'] + stats['pending_pnl_usd']
            roi = (total_pnl / stats['total_cost_usd']) * 100
            print(f"  ç»¼åˆæŠ•èµ„å›æŠ¥ (ROI):    {pnl_color}{roi:.2f}%{reset_color}")

        print("\n" + "=" * 65 + "\n")

    def _save_false_positive_log(self) -> None:
        """ä¿å­˜è¯¯æŠ¥æ—¥å¿—åˆ°æ–‡ä»¶"""
        if self.run_mode == RunMode.DEBUG and self.false_positive_log:
            false_positive_file = Path(self.config.output.output_dir) / f"false_positives_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            false_positive_file.parent.mkdir(parents=True, exist_ok=True)
            with open(false_positive_file, 'w', encoding='utf-8') as f:
                json.dump(self.false_positive_log, f, indent=2, ensure_ascii=False)
            print(f"\n[OK] è¯¯æŠ¥æ—¥å¿—å·²ä¿å­˜: {false_positive_file}")

    def _save_discovered_opportunities(self) -> None:
        """ä¿å­˜æ‰€æœ‰å‘ç°çš„æœºä¼š

        - PRODUCTION æ¨¡å¼ï¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰æœºä¼š
        - DEBUG æ¨¡å¼ï¼šä¸è‡ªåŠ¨ä¿å­˜
        """
        should_save = self.run_mode == RunMode.PRODUCTION

        if should_save and self.discovered_opportunities:
            filename = f"discovered_opportunities_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = Path(self.config.output.output_dir) / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump([json_serialize(opp) for opp in self.discovered_opportunities], f, indent=2, ensure_ascii=False)
            print(f"\n[OK] æ‰€æœ‰å‘ç°çš„æœºä¼šå·²ä¿å­˜: {filepath}")

    def close(self):
        """æ¸…ç†èµ„æº"""
        self.analyzer.close()


# ============================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================

def main():
    """ä¸»ç¨‹åº"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="Polymarketç»„åˆå¥—åˆ©æ‰«æç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€æ‰«æï¼ˆå‘é‡åŒ–æ¨¡å¼ï¼‰
  python local_scanner_v2.py --domain crypto

  # ä½¿ç”¨ç‰¹å®šç­–ç•¥æ‰«æ
  python local_scanner_v2.py --domain crypto --strategies monotonicity
  python local_scanner_v2.py -d crypto --strategies monotonicity,exhaustive --subcat btc,eth

  # ä½¿ç”¨ç‰¹å®šLLMé…ç½®
  python local_scanner_v2.py --profile siliconflow
  python local_scanner_v2.py --profile deepseek --model deepseek-reasoner

  # ä½¿ç”¨æŒ‡å®šç­–ç•¥
  python local_scanner_v2.py --strategies monotonicity,interval
  python local_scanner_v2.py --list-strategies  # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ç­–ç•¥

æŸ¥çœ‹æ‰€æœ‰å¯ç”¨é…ç½®:
  python llm_config.py --list
        """
    )
    parser.add_argument(
        "--profile", "-p",
        type=str,
        help="LLMé…ç½®åç§° (å¦‚: siliconflow, deepseek, ollama, openai)"
    )
    parser.add_argument(
        "--model", "-m",
        type=str,
        help="è¦†ç›–é»˜è®¤æ¨¡å‹ (å¦‚: Qwen/Qwen2.5-72B-Instruct)"
    )
    parser.add_argument(
        "--config", "-c",
        type=str,
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--min-profit",
        type=float,
        help="æœ€å°åˆ©æ¶¦ç™¾åˆ†æ¯” (é»˜è®¤: 2.0)"
    )
    parser.add_argument(
        "--min-apy",
        type=float,
        help="æœ€å°å¹´åŒ–æ”¶ç›Šç‡é—¨æ§› (é»˜è®¤: 15.0)"
    )
    parser.add_argument(
        "--target-size",
        type=float,
        help="æ¨¡æ‹Ÿäº¤æ˜“è§„æ¨¡ USD (é»˜è®¤: 500.0)"
    )
    parser.add_argument(
        "--show-stats",
        action="store_true",
        help="æ˜¾ç¤ºå†å²äº¤æ˜“æ‰§è¡Œç»Ÿè®¡å’Œæ”¶ç›Šæ•°æ® (PnL)"
    )
    parser.add_argument(
        "--sync-settlements",
        action="store_true",
        help="åŒæ­¥å·²å®Œæˆäº¤æ˜“çš„ç»“ç®—çŠ¶æ€å¹¶æ›´æ–° PnL"
    )
    parser.add_argument(
        "--sensitivity-analysis",
        action="store_true",
        help="è¿è¡Œçµæ•åº¦åˆ†æï¼Œæµ‹è¯•ä¸åŒåˆ©æ¶¦é˜ˆå€¼å¯¹æ”¶ç›Šçš„å½±å“ (Phase 5.1)"
    )
    parser.add_argument(
        "--daemon",
        action="store_true",
        help="ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œï¼ŒæŒç»­ç›‘æ§å¹¶æ¨é€é€šçŸ¥ (Phase 9)"
    )
    parser.add_argument(
        "--market-limit",
        type=int,
        help="è·å–å¸‚åœºæ•°é‡ (é»˜è®¤: 200)"
    )
    parser.add_argument(
        "--list-profiles",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„LLMé…ç½®"
    )

    parser.add_argument(
        "--domain", "-d",
        type=str,
        default="crypto",
        choices=["crypto", "politics", "sports", "other"],
        help="å¸‚åœºé¢†åŸŸ (é»˜è®¤: crypto)"
    )
    # ğŸ†• åŠ¨æ€åˆ†ç±»æ§åˆ¶ (v3.1æ–°å¢)
    parser.add_argument(
        "--use-dynamic-categories",
        action="store_true",
        help="å¯ç”¨ LLM åŠ¨æ€åˆ†ç±»å‘ç°"
    )
    parser.add_argument(
        "--list-categories",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å·²å‘ç°çš„å¸‚åœºåˆ†ç±»"
    )
    # ğŸ†• å­ç±»åˆ«ç­›é€‰å‚æ•°ï¼ˆv2.1æ–°å¢ï¼‰
    parser.add_argument(
        "--subcat",
        type=str,
        help="å­ç±»åˆ«ç­›é€‰ (é€—å·åˆ†éš”ï¼Œå¦‚: btc,eth æˆ– bitcoin,ethereum)ã€‚æ”¯æŒç®€å†™ï¼Œå¦‚btcâ†’bitcoin"
    )
    parser.add_argument(
        "--list-subcats",
        action="store_true",
        help="åˆ—å‡ºæŒ‡å®šé¢†åŸŸçš„æ‰€æœ‰å¯ç”¨å­ç±»åˆ«"
    )
    parser.add_argument(
        "--no-interactive",
        action="store_true",
        help="ç¦ç”¨äº¤äº’å¼èœå•ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤é…ç½®"
    )

    # ğŸ†• å›æµ‹å‚æ•° (Phase 6.3)
    parser.add_argument(
        "--backtest",
        action="store_true",
        help="è¿è¡Œå†å²å›æµ‹æ¨¡å¼ (ä½¿ç”¨æœ¬åœ°æ•°æ®åº“)"
    )
    parser.add_argument(
        "--date",
        type=str,
        help="å›æµ‹æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤å…¨éƒ¨"
    )

    # ğŸ†• ç¼“å­˜æ§åˆ¶å‚æ•°ï¼ˆv2.1æ–°å¢ï¼‰
    parser.add_argument(
        "--refresh", "-r",
        action="store_true",
        help="å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°è·å–å¸‚åœºæ•°æ®"
    )
    parser.add_argument(
        "--use-cache",
        action="store_true",
        help="æ˜ç¡®æŒ‡å®šä½¿ç”¨ç¼“å­˜ï¼ˆå¦‚æœç¼“å­˜æœ‰æ•ˆï¼‰"
    )

    # ğŸ†• è¿è¡Œæ¨¡å¼å‚æ•°ï¼ˆv2.2æ–°å¢ï¼‰
    parser.add_argument(
        "--mode",
        type=str,
        choices=["debug", "production"],
        help="è¿è¡Œæ¨¡å¼ (debug=æš‚åœç¡®è®¤, production=è‡ªåŠ¨ä¿å­˜)"
    )

    # ğŸ†• ç­–ç•¥é€‰æ‹©å‚æ•°ï¼ˆv3.1æ–°å¢ï¼‰
    parser.add_argument(
        "--strategies",
        type=str,
        help="é€‰æ‹©å¥—åˆ©ç­–ç•¥ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œå¦‚: monotonicity,exhaustive,implication,equivalent,intervalã€‚é»˜è®¤: å…¨éƒ¨"
    )
    # ğŸ†• é«˜é¢‘æ¨¡å¼å‚æ•° (Phase 5.3)
    parser.add_argument(
        "--loop",
        action="store_true",
        help="å¯ç”¨æŒç»­æ‰«ææ¨¡å¼"
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=300,
        help="ä¸¤æ¬¡æ‰«æä¹‹é—´çš„é—´éš”ç§’æ•° (é»˜è®¤: 300)"
    )
    parser.add_argument(
        "--list-strategies",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¥—åˆ©ç­–ç•¥"
    )

    # ğŸ†• Tagåˆ†ç±»ç®¡ç†å‚æ•°ï¼ˆv3.2æ–°å¢ï¼‰
    parser.add_argument(
        "--refine-other",
        action="store_true",
        help="ç»†åˆ†Otheråˆ†ç±»ï¼ˆå¯¹å·²æ ‡è®°ä¸ºotherçš„tagsè¿›è¡ŒäºŒæ¬¡åˆ†ç±»åˆ°finance/tech/entertainment/science/weather/miscï¼‰"
    )

    args = parser.parse_args()

    # ============================================================
    # ğŸ†• åˆ—å‡ºå¯ç”¨ç­–ç•¥ï¼ˆv3.1æ–°å¢ï¼‰
    # ============================================================
    if args.list_strategies:
        if CLI_AVAILABLE and StrategyRegistry:
            print("\n=== å¯ç”¨çš„å¥—åˆ©ç­–ç•¥ ===\n")
            all_strategies = StrategyRegistry.get_all()
            for s in all_strategies:
                risk_str = s.risk_level.value if hasattr(s.risk_level, 'value') else s.risk_level
                llm_str = "æ˜¯" if s.requires_llm else "å¦"
                domains_str = ", ".join(s.domains)
                print(f"  ID: {s.id}")
                print(f"    åç§°: {s.name} ({s.name_en})")
                print(f"    æè¿°: {s.description}")
                print(f"    ä¼˜å…ˆçº§: {s.priority} | éœ€è¦LLM: {llm_str} | é£é™©: {risk_str.upper()}")
                print(f"    é€‚ç”¨é¢†åŸŸ: {domains_str}")
                print(f"    æœ€ä½åˆ©æ¶¦: {s.min_profit_threshold}%")
                print()
            print(f"å…± {len(all_strategies)} ä¸ªç­–ç•¥å¯ç”¨")
            print("\nä½¿ç”¨ --strategies å‚æ•°é€‰æ‹©ç­–ç•¥ï¼Œå¦‚:")
            print("  python local_scanner_v2.py --strategies monotonicity,exhaustive")
            return 0
        else:
            print("[ERROR] CLI æ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åˆ—å‡ºç­–ç•¥")
            print("       è¯·ç¡®ä¿å·²å®‰è£… rich å’Œ questionary: pip install -r requirements.txt")
            return 1

    # ============================================================
    # ğŸ†• ç»†åˆ†Otheråˆ†ç±» (v3.2æ–°å¢)
    # ============================================================
    if args.refine_other:
        try:
            from cli.tag_classifier import classify_tags_interactive
            print("\n=== ç»†åˆ†Otheråˆ†ç±» ===\n")
            print("å°†otherç±»åˆ«çš„tagsé‡æ–°åˆ†ç±»åˆ°ç»†åˆ†ç±»åˆ«ï¼š")
            print("  - finance (ä¼ ç»Ÿé‡‘è)")
            print("  - tech (ç§‘æŠ€/AI)")
            print("  - entertainment (å¨±ä¹/æ–‡åŒ–)")
            print("  - science (ç§‘å­¦/ç ”ç©¶)")
            print("  - weather (å¤©æ°”/è‡ªç„¶)")
            print("  - misc (æ‚é¡¹)")
            print()

            success = classify_tags_interactive(
                menu=None,
                llm_profile=args.profile,
                mode='refine'  # ä¼ å…¥refineæ¨¡å¼
            )
            return 0 if success else 1
        except Exception as e:
            print(f"[ERROR] ç»†åˆ†åˆ†ç±»å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 1

    # ============================================================
    # ğŸ†• åˆ—å‡ºå·²å‘ç°åˆ†ç±» (v3.1æ–°å¢)
    # ============================================================
    if args.list_categories:
        # åŠ è½½é…ç½®
        config = AppConfig.load(args.config)
        scanner = ArbitrageScanner(config, profile_name=args.profile)
        # å¼ºåˆ¶å¯ç”¨åŠ¨æ€åˆ†ç±»ä»¥ä¾¿åŠ è½½/å‘ç°
        scanner.use_dynamic_categories = True
        categories = scanner.get_available_categories()

        print("\n=== å·²å‘ç°çš„å¸‚åœºåˆ†ç±» ===\n")
        if not categories:
            print("  [æç¤º] å°šæœªå‘ç°ä»»ä½•åŠ¨æ€åˆ†ç±»ã€‚è¯·è¿è¡Œæ‰«æå¹¶å¯ç”¨ --use-dynamic-categoriesã€‚")
        else:
            for i, cat in enumerate(categories, 1):
                icon = cat.icon or "ğŸ“"
                print(f"  {i:2d}. {icon} {cat.name_zh} ({cat.name_en})")
                print(f"      æè¿°: {cat.description}")
                print(f"      å¸‚åœºæ•°: {cat.market_count} | ç½®ä¿¡åº¦: {cat.discovery_confidence:.0%}")
                print(f"      Tags: {', '.join(cat.representative_tags)}")
                print()
            print(f"å…± {len(categories)} ä¸ªåˆ†ç±»å¯ç”¨")
        return 0

    # ============================================================
    # ğŸ†• æ˜¾ç¤ºäº¤æ˜“æ‰§è¡Œç»Ÿè®¡ï¼ˆPhase 4.6/4.7 æ–°å¢ï¼‰
    # ============================================================
    if getattr(args, 'show_stats', False):
        config = AppConfig.load(args.config)
        scanner = ArbitrageScanner(config, profile_name=args.profile)
        scanner._show_execution_stats()
        return 0

    # ============================================================
    # ğŸ†• å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ (Phase 9)
    # ============================================================
    if getattr(args, 'daemon', False):
        print("[INFO] å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ (Daemon Mode)...")
        print("æŒ‰ Ctrl+C åœæ­¢")

        try:
            config = AppConfig.load(args.config)
            scanner = ArbitrageScanner(config, profile_name=args.profile)

            # å¯åŠ¨ WebSocket (å¦‚æœé…ç½®å…è®¸)
            # åœ¨å…¨è‡ªåŠ¨æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬é»˜è®¤è®¢é˜…çƒ­é—¨èµ„äº§æˆ–å…¨éƒ¨å‘ç°çš„èµ„äº§
            # è¿™é‡Œå…ˆæ‰§è¡Œä¸€æ¬¡å…¨é‡æ‰«ææ¥åˆå§‹åŒ–è®¢é˜…åˆ—è¡¨
            print("[DAEMON] æ‰§è¡Œåˆå§‹å…¨é‡æ‰«æ...")
            scanner.scan_semantic(
                domain=args.domain,
                subcategories=args.subcat.split(",") if args.subcat else None
            )

            print(f"[DAEMON] è¿›å…¥æŒç»­ç›‘æ§å¾ªç¯ (é—´éš”: {config.scan.scan_interval}s)...")

            while True:
                time.sleep(config.scan.scan_interval)
                print(f"\n[DAEMON] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} å¼€å§‹å®šæœŸæ‰«æ...")

                # é‡æ–°æ‰«æä»¥å‘ç°æ–°å¸‚åœº
                scanner.scan_semantic(
                    domain=args.domain,
                    subcategories=args.subcat.split(",") if args.subcat else None
                )

        except KeyboardInterrupt:
            print("\n[DAEMON] æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
            if hasattr(scanner, 'stop_websocket'):
                scanner.stop_websocket()
        except Exception as e:
            logging.error(f"[DAEMON] å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            traceback.print_exc()
            return 1

        return 0

    # ============================================================
    # ğŸ†• çµæ•åº¦åˆ†æï¼ˆPhase 5.1 æ–°å¢ï¼‰
    # ============================================================
    if getattr(args, 'sensitivity_analysis', False):
        config = AppConfig.load(args.config)
        scanner = ArbitrageScanner(config, profile_name=args.profile)
        engine = BacktestEngine(scanner)

        # ç¡®å®šæ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤å›æµ‹æœ€è¿‘ 24 å°æ—¶ï¼‰
        ts = engine.get_available_timestamps()
        if not ts:
            print("[ERROR] æ•°æ®åº“ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œçµæ•åº¦åˆ†æã€‚è¯·å…ˆè¿è¡Œæ‰«æç§¯ç´¯æ•°æ®ã€‚")
            return 1

        end_time = ts[-1]
        start_time = (datetime.fromisoformat(end_time) - timedelta(days=1)).isoformat()

        # å®šä¹‰æµ‹è¯•é˜ˆå€¼åˆ—è¡¨
        thresholds = [0.005, 0.01, 0.015, 0.02, 0.03, 0.05]

        engine.run_sensitivity_analysis(start_time, end_time, thresholds)
        return 0

    # ============================================================
    # ğŸ†• åŒæ­¥ç»“ç®—çŠ¶æ€ï¼ˆPhase 4.8 æ–°å¢ï¼‰
    # ============================================================
    if getattr(args, 'sync_settlements', False):
        config = AppConfig.load(args.config)
        scanner = ArbitrageScanner(config, profile_name=args.profile)
        scanner.sync_settlements()
        return 0

    # ============================================================
    # ğŸ†• åˆ—å‡ºå­ç±»åˆ«ï¼ˆv2.1æ–°å¢ï¼‰- éœ€è¦åœ¨äº¤äº’å¼é€‰æ‹©ä¹‹å‰å¤„ç†
    # ============================================================
    if args.list_subcats:
        # ç›´æ¥è¯»å–tag_categories.json
        tag_categories_file = Path(__file__).parent / "data" / "tag_categories.json"
        if tag_categories_file.exists():
            with open(tag_categories_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            print(f"[ERROR] æ ‡ç­¾åˆ†ç±»æ–‡ä»¶ä¸å­˜åœ¨: {tag_categories_file}")
            return 1

        # ä¼˜å…ˆæ˜¾ç¤ºåˆ†ç»„
        groups = data.get("groups", {}).get(args.domain, {})
        if groups:
            print(f"\n=== {args.domain.upper()} å­ç±»åˆ«åˆ†ç»„ ===\n")
            for group_name, tags in groups.items():
                print(f"[{group_name}] ({len(tags)}ä¸ªæ ‡ç­¾):")
                for tag in sorted(tags):
                    print(f"   - {tag}")
                print()

            all_tags = data.get("categories", {}).get(args.domain, [])
            print(f"å…± {len(all_tags)} ä¸ªæ ‡ç­¾ï¼Œå·²åˆ†ä¸º {len(groups)} ä¸ªåˆ†ç»„")

            print("\næç¤º: åœ¨äº¤äº’æ¨¡å¼ä¸­é€‰æ‹©åˆ†ç»„åï¼Œä¼šè‡ªåŠ¨åŒ…å«è¯¥åˆ†ç»„ä¸‹çš„æ‰€æœ‰æ ‡ç­¾")
            print("      CLIæ¨¡å¼å¯ä½¿ç”¨: --subcat bitcoin,ethereum")
        elif args.domain in data.get("categories", {}):
            print(f"\n=== {args.domain.upper()} å¯ç”¨å­ç±»åˆ« ===")
            subcats = sorted(data["categories"][args.domain])
            print(f"å…± {len(subcats)} ä¸ªå­ç±»åˆ«:\n")
            for i, subcat in enumerate(subcats, 1):
                print(f"  {i:2d}. {subcat}")
            print("\næç¤º: å¯ä½¿ç”¨ç®€å†™ï¼Œå¦‚ btcâ†’bitcoinã€ethâ†’ethereum")
            print("      ä½¿ç”¨ --subcat å‚æ•°è¿›è¡Œç­›é€‰ï¼Œå¦‚: --subcat bitcoin,ethereum")
        else:
            print(f"[ERROR] é¢†åŸŸ '{args.domain}' æ²¡æœ‰å¯ç”¨çš„å­ç±»åˆ«")
            return 1
        return 0

    # ============================================================
    # ğŸ†• äº¤äº’å¼é…ç½®æ”¶é›†ï¼ˆv3.1é‡æ„ï¼‰
    # ============================================================
    # ç¡®å®šæ˜¯å¦ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•
    use_new_menu = CLI_AVAILABLE and not args.no_interactive and not getattr(args, 'backtest', False)

    # åˆå§‹åŒ–è¾“å‡º
    if use_new_menu:
        output = ScannerOutput()
        output.welcome("v3.1")
    else:
        output = None

    # ç¡®å®šè¦æ‰«æçš„é¢†åŸŸ
    domain = args.domain  # é»˜è®¤ä¸º "crypto"

    if use_new_menu:
        # åˆ›å»ºæŒä¹…çš„èœå•å¯¹è±¡ï¼ˆæ•´ä¸ªä¼šè¯å…±äº«ï¼Œä¿å­˜LLMé…ç½®ç­‰çŠ¶æ€ï¼‰
        menu = InteractiveMenu()

        # ğŸ†• æ˜¾ç¤ºå½“å‰LLMé…ç½®ï¼ˆv3.3æ–°å¢ï¼‰
        menu.display_current_llm_config()

        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•ï¼ˆå¾ªç¯å¤„ç†ï¼Œæ”¯æŒè¿ç»­æ“ä½œï¼‰
        while True:
            action = menu.main_menu()
            if action == "exit":
                print("[INFO] é€€å‡ºç¨‹åº")
                return 0
            elif action == "help":
                menu.show_help()
                # ç»§ç»­å¾ªç¯ï¼Œæ˜¾ç¤ºä¸»èœå•
                continue
            elif action == "classify_tags":
                # Tagsæ™ºèƒ½åˆ†ç±»ï¼ˆä¼šä½¿ç”¨menuä¸­ä¿å­˜çš„LLMé…ç½®ï¼‰
                menu.tags_classify_menu()
                # ç»§ç»­å¾ªç¯ï¼Œæ˜¾ç¤ºä¸»èœå•
                continue
            elif action == "config":
                # TODO: å®ç°é…ç½®èœå•
                print("[INFO] é…ç½®èœå•åŠŸèƒ½å¾…å®ç°")
                # ç»§ç»­å¾ªç¯ï¼Œæ˜¾ç¤ºä¸»èœå•
                continue
            elif action == "llm_config":
                # å¤„ç†LLMé…ç½®é€‰æ‹©
                llm_config_result = menu.select_llm_profile()

                if llm_config_result:
                    selected_profile = llm_config_result.get('profile', 'unknown')
                    selected_model = llm_config_result.get('model', 'default')
                    print(f"[green]âœ“ å·²é€‰æ‹©LLMé…ç½®: {selected_profile} - {selected_model}[/green]")
                    print("[dim]æç¤º: æœ¬æ¬¡ä¼šè¯å°†ä½¿ç”¨æ­¤é…ç½®[/dim]")
                else:
                    print("[yellow]âš  æœªé€‰æ‹©LLMé…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®[/yellow]")

                # ç»§ç»­å¾ªç¯ï¼Œæ˜¾ç¤ºä¸»èœå•
                continue
            elif action == "sensitivity_analysis":
                # è¿è¡Œçµæ•åº¦åˆ†æ
                try:
                    app_config = AppConfig.load(args.config)
                    scanner = ArbitrageScanner(app_config, profile_name=args.profile)
                    engine = BacktestEngine(scanner)

                    ts = engine.get_available_timestamps()
                    if not ts:
                        print("[ERROR] æ•°æ®åº“ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œçµæ•åº¦åˆ†æã€‚è¯·å…ˆè¿è¡Œæ‰«æç§¯ç´¯æ•°æ®ã€‚")
                        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                        continue

                    # é»˜è®¤æœ€è¿‘ 24 å°æ—¶
                    end_time = ts[-1]
                    start_time = (datetime.fromisoformat(end_time.replace('Z', '+00:00')) - timedelta(days=1)).isoformat()

                    # æç¤ºç”¨æˆ·ç¡®è®¤æ—¶é—´èŒƒå›´æˆ–ä½¿ç”¨é»˜è®¤
                    print(f"\n[INFO] çµæ•åº¦åˆ†ææ—¶é—´èŒƒå›´: {start_time} -> {end_time}")
                    confirm = input("æ˜¯å¦ä»¥æ­¤èŒƒå›´è¿è¡Œ? (y=æ˜¯, n=è¿›å…¥å›æµ‹èœå•è‡ªå®šä¹‰, ç›´æ¥å›è½¦=y): ").strip().lower()

                    if confirm == 'n':
                        print("  -> è¯·åœ¨ 'å†å²å›æµ‹' èœå•ä¸­è‡ªå®šä¹‰é«˜çº§å‚æ•°ã€‚")
                        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                        continue

                    thresholds = [0.005, 0.01, 0.015, 0.02, 0.03, 0.05]
                    engine.run_sensitivity_analysis(start_time, end_time, thresholds)
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                except Exception as e:
                    print(f"[ERROR] çµæ•åº¦åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                continue
            elif action == "sync_settlements":
                # åŒæ­¥ç»“ç®—çŠ¶æ€
                try:
                    app_config = AppConfig.load(args.config)
                    scanner = ArbitrageScanner(app_config, profile_name=args.profile)
                    scanner.sync_settlements()
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                except Exception as e:
                    print(f"[ERROR] åŒæ­¥ç»“ç®—çŠ¶æ€å¤±è´¥: {e}")
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                continue
            elif action == "stats":
                # æ˜¾ç¤º PnL ç»Ÿè®¡æ•°æ®
                try:
                    app_config = AppConfig.load(args.config)
                    scanner = ArbitrageScanner(app_config, profile_name=args.profile)
                    scanner._show_execution_stats()
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                except Exception as e:
                    print(f"[ERROR] è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                continue
            elif action == "backtest":
                # æ”¶é›†å›æµ‹é…ç½®
                bt_config = menu.gather_backtest_config()
                if not bt_config:
                    continue
                
                # ä¸´æ—¶åŠ è½½é…ç½®ç”¨äºå›æµ‹
                try:
                    # åŠ è½½åŸºç¡€é…ç½®
                    app_config = AppConfig.load(args.config)
                    
                    # ç¡®å®šä½¿ç”¨çš„ LLM Profile (ä¼˜å…ˆä½¿ç”¨èœå•é€‰æ‹©çš„ï¼Œå…¶æ¬¡æ˜¯å‘½ä»¤è¡Œçš„)
                    profile_to_use = args.profile
                    model_to_use = args.model
                    
                    if menu.current_llm_profile:
                        profile_to_use = menu.current_llm_profile.get("profile")
                        model_to_use = menu.current_llm_profile.get("model")
                        
                    # åˆå§‹åŒ–æ‰«æå™¨
                    scanner = ArbitrageScanner(
                        app_config,
                        profile_name=profile_to_use,
                        model_override=model_to_use
                    )
                    
                    # åˆå§‹åŒ–å›æµ‹å¼•æ“
                    engine = BacktestEngine(scanner)
                    
                    # è¿è¡Œå›æµ‹
                    engine.run_backtest(
                        start_time=bt_config["start_time"],
                        end_time=bt_config["end_time"],
                        strategies=bt_config["strategies"]
                    )
                    
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                except Exception as e:
                    print(f"[ERROR] å›æµ‹å¯åŠ¨å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                
                continue
            elif action == "scan":
                # å¼€å§‹æ‰«ææµç¨‹ï¼Œè·³å‡ºå¾ªç¯
                break
            else:
                print(f"[WARNING] æœªçŸ¥æ“ä½œ: {action}")
                return 0

        # action == "scan" ç»§ç»­ï¼Œç¨ååœ¨åˆå§‹åŒ– scanner åé€‰æ‹©ç±»åˆ«
        pass

    # åˆ—å‡ºé…ç½®
    if args.list_profiles:
        from llm_config import LLMConfigManager, print_profiles_table
        manager = LLMConfigManager()
        print_profiles_table(manager.list_profiles())
        return 0

    # åŠ è½½é…ç½®
    config = AppConfig.load(args.config)

    # è¦†ç›–é…ç½®
    if args.min_profit:
        config.scan.min_profit_pct = args.min_profit
    if hasattr(args, 'min_apy') and args.min_apy:
        config.scan.min_apy = args.min_apy
    if hasattr(args, 'target_size') and args.target_size:
        config.scan.target_size_usd = args.target_size
    if args.market_limit:
        config.scan.market_limit = args.market_limit

    # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„ profile_name
    # ä¼˜å…ˆçº§: 1. äº¤äº’èœå•ä¸­é€‰æ‹©çš„ (menu.current_llm_profile)
    #        2. å‘½ä»¤è¡Œå‚æ•° (args.profile)
    #        3. é…ç½®æ–‡ä»¶ä¸­çš„ active_profile (config.active_profile)
    final_profile_name = args.profile
    final_model_override = args.model

    if use_new_menu:
        if menu.current_llm_profile:
            final_profile_name = menu.current_llm_profile
        if menu.current_llm_model:
            final_model_override = menu.current_llm_model

    # å¦‚æœä»ä¸ºç©ºï¼Œå›é€€åˆ°é…ç½®æ–‡ä»¶çš„ active_profile
    if not final_profile_name and config.active_profile:
        final_profile_name = config.active_profile
        # å¦‚æœä½¿ç”¨äº† config.active_profileï¼Œä¹Ÿæ£€æŸ¥ä¸€ä¸‹æ˜¯å¦æœ‰å¯¹åº”çš„ model é…ç½®
        # (ArbitrageScanner å†…éƒ¨ä¼šå¤„ç†ï¼Œä½†è¿™é‡Œä¸ºäº†æ˜ç¡®æ€§å¯ä»¥ä¸åš)

    # è¿è¡Œæ¨¡å¼é€‰æ‹©
    run_mode = None
    if args.mode:
        # å‘½ä»¤è¡Œæ˜ç¡®æŒ‡å®šæ¨¡å¼
        run_mode = RunMode(args.mode)
        print(f"[INFO] è¿è¡Œæ¨¡å¼: {args.mode.upper()}")
    elif use_new_menu:
        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•é€‰æ‹©æ¨¡å¼
        run_mode_str = menu.select_run_mode()
        run_mode = RunMode(run_mode_str)

    if run_mode is None:
        # é»˜è®¤ï¼šç”Ÿäº§æ¨¡å¼
        run_mode = RunMode.PRODUCTION
        print("[INFO] è¿è¡Œæ¨¡å¼: PRODUCTION (é»˜è®¤)")

    # åˆå§‹åŒ–æ‰«æå™¨
    scanner = ArbitrageScanner(
        config,
        profile_name=final_profile_name,
        model_override=final_model_override,
        run_mode=run_mode
    )

    # ğŸ†• å›æµ‹æ¨¡å¼å…¥å£ (Phase 6.3)
    if getattr(args, 'backtest', False):
        try:
            print("[INFO] å¯åŠ¨å†å²å›æµ‹æ¨¡å¼...")
            engine = BacktestEngine(scanner)

            # ç¡®å®šå›æµ‹æ—¶é—´èŒƒå›´
            target_date = getattr(args, 'date', None)
            if target_date:
                start_time = f"{target_date}T00:00:00"
                end_time = f"{target_date}T23:59:59"
            else:
                # é»˜è®¤æ¶µç›–æ‰€æœ‰è®°å½•
                start_time = "2024-01-01T00:00:00"
                end_time = datetime.now().isoformat()

            engine.run_backtest(start_time, end_time)
            return 0
        except Exception as e:
            logging.error(f"å›æµ‹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 1

    # âœ… å¯ç”¨åŠ¨æ€åˆ†ç±» (v3.1æ–°å¢)
    scanner.use_dynamic_categories = args.use_dynamic_categories or getattr(config.scan, 'use_dynamic_categories', False)

    # ============================================================
    # ğŸ†• ç±»åˆ«é€‰æ‹© (v3.1é‡æ„)
    # ============================================================
    selected_category = None
    available_categories = scanner.get_available_categories()

    if use_new_menu:
        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•é€‰æ‹©ç±»åˆ«
        selected_category = menu.select_category(scanner)
    else:
        # éäº¤äº’æ¨¡å¼ï¼šé€šè¿‡ ID åŒ¹é…å‘½ä»¤è¡ŒæŒ‡å®šçš„ domain
        selected_category = next((c for c in available_categories if c.id == domain), None)
        if not selected_category:
            # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯ cryptoï¼‰
            selected_category = available_categories[0]
            print(f"[INFO] æœªæ‰¾åˆ°åŒ¹é…ç±»åˆ« '{domain}'ï¼Œä½¿ç”¨é»˜è®¤: {selected_category.name_zh}")

    # æ›´æ–° domain å˜é‡ä¸ºæœ€ç»ˆé€‰å®šçš„ç±»åˆ« IDï¼Œä»¥ä¿æŒåç»­é€»è¾‘å…¼å®¹
    domain = selected_category.id
    try:
        print(f"[INFO] æ‰«æç±»åˆ«: {selected_category.icon} {selected_category.name_zh} ({selected_category.name_en})")
    except UnicodeEncodeError:
        # Fallback for environments that don't support special icons/characters
        print(f"[INFO] æ‰«æç±»åˆ«: {selected_category.name_zh} ({selected_category.name_en})")

    # ============================================================
    # ç­–ç•¥é€‰æ‹©
    # ============================================================
    # ç¡®å®šè¦æ‰§è¡Œçš„å¥—åˆ©ç­–ç•¥
    selected_strategy_ids = None

    if args.strategies:
        # å‘½ä»¤è¡ŒæŒ‡å®šç­–ç•¥
        selected_strategy_ids = [s.strip() for s in args.strategies.split(",")]
        print(f"[INFO] ä½¿ç”¨æŒ‡å®šç­–ç•¥: {', '.join(selected_strategy_ids)}")
    elif use_new_menu:
        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•é€‰æ‹©ç­–ç•¥
        selected_strategy_ids = menu.select_strategies(domain)
        print(f"[INFO] å·²é€‰æ‹©ç­–ç•¥: {', '.join(selected_strategy_ids)}")

    # å¦‚æœæ²¡æœ‰é€‰æ‹©ç­–ç•¥ï¼Œä½¿ç”¨è¯¥é¢†åŸŸçš„æ‰€æœ‰å¯ç”¨ç­–ç•¥
    if selected_strategy_ids is None:
        available = StrategyRegistry.get_for_domain(domain)
        selected_strategy_ids = [m.id for m in available]
        print(f"[INFO] ä½¿ç”¨é»˜è®¤ç­–ç•¥: {', '.join(selected_strategy_ids)}")

    # å­ç±»åˆ«é€‰æ‹©
    subcategories = None
    if args.subcat:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„å­ç±»åˆ«
        raw_subcats = [s.strip() for s in args.subcat.split(",")]

        # åº”ç”¨ç®€å†™æ˜ å°„
        expanded = []
        for s in raw_subcats:
            mapped = SUBCATEGORY_ALIASES.get(s.lower(), s)
            expanded.append(mapped)

        # ğŸ†• æ”¹è¿›çš„éªŒè¯é€»è¾‘ï¼šå…è®¸ä¸å­˜åœ¨çš„å­ç±»åˆ«ï¼ˆä¼šè‡ªåŠ¨æ‰©å±•ä¸ºç›¸å…³æ ‡ç­¾ï¼‰
        tag_categories_file = Path(__file__).parent / "data" / "tag_categories.json"
        if tag_categories_file.exists():
            with open(tag_categories_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                tag_categories = data.get("categories", {})

            all_tags = tag_categories.get(domain, [])

            # æ£€æŸ¥æ¯ä¸ªå­ç±»åˆ«æ˜¯å¦èƒ½æ‰©å±•ä¸ºæœ‰æ•ˆæ ‡ç­¾
            final_subcats = []
            for subcat in expanded:
                # æ£€æŸ¥æ˜¯å¦ç›´æ¥æœ‰æ•ˆ
                if subcat in all_tags:
                    final_subcats.append(subcat)
                else:
                    # å°è¯•æ‰©å±•ä¸ºç›¸å…³æ ‡ç­¾
                    related = [t for t in all_tags if subcat.lower() in t.lower()]
                    if related:
                        print(f"[INFO] '{subcat}' æ‰©å±•ä¸º: {', '.join(related)}")
                        final_subcats.extend(related)
                    else:
                        print(f"[WARNING] æ— æ•ˆçš„å­ç±»åˆ«å°†è¢«å¿½ç•¥: {subcat} (æ²¡æœ‰ç›¸å…³æ ‡ç­¾)")

            expanded = final_subcats

        if expanded:
            subcategories = expanded
            print(f"[INFO] å­ç±»åˆ«ç­›é€‰: {', '.join(sorted(set(expanded)))}")
    elif use_new_menu:
        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•é€‰æ‹©å­ç±»åˆ«
        subcategories = menu.select_subcategories(domain)
        if subcategories:
            print(f"[INFO] å·²é€‰æ‹©å­ç±»åˆ«: {', '.join(subcategories)}")

    # ============================================================
    # ğŸ†• ç¼“å­˜é€‰æ‹©ï¼ˆv3.1é‡æ„ï¼‰
    # ============================================================
    force_refresh = False

    if args.refresh:
        # CLIå‚æ•°æ˜ç¡®æŒ‡å®šåˆ·æ–°
        force_refresh = True
        print("[INFO] å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œå°†é‡æ–°è·å–å¸‚åœºæ•°æ®")
    elif args.use_cache:
        # CLIå‚æ•°æ˜ç¡®æŒ‡å®šä½¿ç”¨ç¼“å­˜
        force_refresh = False
        print("[INFO] ä½¿ç”¨ç¼“å­˜æ¨¡å¼")
    elif use_new_menu:
        # ä½¿ç”¨æ–°çš„äº¤äº’å¼èœå•é€‰æ‹©ç¼“å­˜é€‰é¡¹
        force_refresh = menu.select_cache_option()
        if output:
            if force_refresh:
                output.print_info("å°†é‡æ–°è·å–å¸‚åœºæ•°æ®")
            else:
                output.print_info("ä½¿ç”¨ç¼“å­˜æ•°æ®")

    # ============================================================
    # ğŸ†• é…ç½®ç¡®è®¤ï¼ˆv3.1æ–°å¢ï¼‰
    # ============================================================
    if use_new_menu:
        config_dict = {
            "domain": domain,
            "strategies": selected_strategy_ids or ["å…¨éƒ¨"],
            "subcategories": subcategories or ["å…¨éƒ¨"],
            "mode": run_mode.value,
            "force_refresh": force_refresh
        }
        if not menu.confirm_config(config_dict):
            print("[INFO] å–æ¶ˆæ‰«æ")
            return 0

    # ============================================================
    # ğŸ†• æ‰«ææ‰§è¡Œ (v3.1é‡æ„ / Phase 5.3 é«˜é¢‘æ¨¡å¼)
    # ============================================================
    import time

    def perform_scan_task():
        """æ‰§è¡Œå•æ¬¡æ‰«æä»»åŠ¡"""
        start_time = time.time()
        opportunities = []
        try:
            if output:
                output.print_step(1, 2, "è·å–å¸‚åœºæ•°æ®...")

            # è·å–å¸‚åœºæ•°æ®
            if scanner.use_dynamic_categories:
                markets = scanner.fetch_markets_for_category(selected_category, limit=config.scan.market_limit, force_refresh=force_refresh)
            else:
                markets = scanner._fetch_domain_markets(domain, subcategories, force_refresh)

            if output:
                output.print_market_fetch(len(markets), domain, subcategories)

            # âœ… è®°å½•å¸‚åœºä»·æ ¼å¿«ç…§ (Phase 6.1)
            if hasattr(scanner, 'recorder'):
                scanner.recorder.record_markets(markets)

            if output:
                output.print_step(2, 2, "æ‰§è¡Œå¥—åˆ©ç­–ç•¥...")

            # âœ… æ‰§è¡Œè¯­ä¹‰èšç±»å‘ç°å…³è”å¸‚åœº (Phase 5.1)
            clusters = []
            if getattr(config.scan, 'use_semantic_clustering', True) and scanner.clusterer:
                try:
                    # ä»…å¯¹æµåŠ¨æ€§è¾¾æ ‡çš„å¸‚åœºè¿›è¡Œèšç±»ä»¥èŠ‚çœè®¡ç®—èµ„æº
                    cluster_candidates = [m for m in markets if m.liquidity >= getattr(config.scan, 'min_liquidity', 1000)]
                    if len(cluster_candidates) >= 2:
                        clusters = scanner.clusterer.cluster_markets(
                            cluster_candidates,
                            similarity_threshold=getattr(config.scan, 'semantic_threshold', 0.85)
                        )
                        if output:
                            output.print_info(f"è¯­ä¹‰èšç±»å‘ç° {len(clusters)} ä¸ªå…³è”ç°‡")
                except Exception as e:
                    logging.warning(f"è¯­ä¹‰èšç±»å¤±è´¥: {e}")

            # âœ… æ‰¹é‡èšç±»æ·±åº¦åˆ†æ (Phase 5.2 ä¼˜åŒ–)
            # å¦‚æœå¯ç”¨äº†èšç±»ä¸”é€‰æ‹©äº†é€»è¾‘ç±»ç­–ç•¥ï¼Œåˆ™æ‰§è¡Œæ‰¹é‡åˆ†æä»¥èŠ‚çœ Token å¹¶æå‡å¬å›ç‡
            logic_strategy_ids = ['implication', 'equivalent']
            logic_strategy_active = any(s_id in selected_strategy_ids for s_id in logic_strategy_ids)

            if clusters and logic_strategy_active:
                if output:
                    output.print_step(2, 2, f"æ­£åœ¨å¯¹ {len(clusters)} ä¸ªè¯­ä¹‰ç°‡è¿›è¡Œæ‰¹é‡é€»è¾‘æŒ–æ˜...")

                for i, cluster in enumerate(clusters):
                    if len(cluster) < 2:
                        continue

                    try:
                        batch_opps = scanner._analyze_cluster_fully(cluster)
                        if batch_opps:
                            # æ’é™¤æ‰å·²ç»é€šè¿‡ç­–ç•¥å‘ç°çš„é‡å¤æœºä¼š
                            for b_opp in batch_opps:
                                if not any(o.id == b_opp.id for o in opportunities):
                                    opportunities.append(b_opp)
                                    if output:
                                        output.print_opportunity(b_opp)
                    except Exception as e:
                        logging.debug(f"æ‰¹é‡åˆ†æç°‡ {i+1} å¤±è´¥: {e}")

            # æŒ‰ä¼˜å…ˆçº§è·å–ç­–ç•¥å¹¶æ‰§è¡Œ
            strategies = StrategyRegistry.get_by_ids(selected_strategy_ids)

            for strategy in strategies:
                # âœ… ä¿®æ­£ï¼šä½¿ç”¨ strategy.metadata.id (Phase 5.2 ä¿®å¤)
                if strategy.metadata.id in logic_strategy_ids and clusters:
                    continue

                if output:
                    output.print_strategy_start(strategy.metadata.name)

                try:
                    opps = strategy.scan(
                        markets,
                        {
                            "min_profit_pct": config.scan.min_profit_pct,
                            "domain": domain,
                            "subcategories": subcategories,
                            "scan": config.scan,  # ä¼ å…¥å®Œæ•´é…ç½®
                            "analyzer": scanner.analyzer,  # ä¼ å…¥ LLM åˆ†æå™¨
                            "clusters": clusters  # ğŸ†• ä¼ å…¥è¯­ä¹‰èšç±»ç»“æœ (Phase 5.1)
                        },
                        progress_callback=lambda curr, total, msg: (
                            output.print_step(1, len(strategies), msg) if output else None
                        ) if output else None
                    )

                    # âœ… æ‰§è¡Œäº”å±‚éªŒè¯ä¸é£æ§å¡«å…… (Phase 2.5)
                    valid_opps = []
                    for opp in opps:
                        validated_opp = scanner._validate_and_enrich_opportunity(opp, markets)
                        if validated_opp:
                            valid_opps.append(validated_opp)

                    opportunities.extend(valid_opps)

                    if output:
                        output.print_strategy_result(strategy.metadata.name, len(valid_opps))

                except Exception as e:
                    if output:
                        output.print_error(f"{strategy.metadata.name} æ‰§è¡Œå¤±è´¥: {e}")

            # ä¿å­˜æŠ¥å‘Š
            if opportunities:
                scanner._save_report(opportunities, domain)

                # âœ… è®°å½•å¥—åˆ©æœºä¼šå­˜ç»­å†å² (Phase 6.1)
                if hasattr(scanner, 'recorder'):
                    scanner.recorder.record_opportunities(opportunities)

                if output:
                    output.print_report_saved(
                        Path(scanner.config.output.output_dir) / f"scan_{domain}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    )

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            elapsed_time = time.time() - start_time
            if output:
                output.print_summary(opportunities, elapsed_time)
            else:
                print("\n" + "=" * 65)
                print("æ‰«æå®Œæˆï¼")
                print("=" * 65)

            if opportunities:
                print("\nä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
                print("  1. ä»”ç»†é˜…è¯»æ¯ä¸ªæœºä¼šçš„å¤æ ¸é¡¹ç›®")
                print("  2. åœ¨Polymarketä¸ŠéªŒè¯å½“å‰ä»·æ ¼")
                print("  3. é˜…è¯»å¸‚åœºçš„ç»“ç®—è§„åˆ™")
                print("  4. å°é¢æµ‹è¯•ï¼ˆ$10-50ï¼‰")

            return len(opportunities)

        except Exception as e:
            import traceback
            logging.error(f"æ‰«ææ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
            traceback.print_exc()
            return -1

    # é€»è¾‘æ§åˆ¶ï¼šå•æ¬¡æ‰«æ vs é«˜é¢‘å¾ªç¯æ¨¡å¼ (Phase 5.3)
    if not getattr(args, 'loop', False):
        try:
            return perform_scan_task()
        finally:
            scanner.close()
    else:
        # è¿›å…¥é«˜é¢‘å¾ªç¯æ¨¡å¼
        iteration = 1
        interval = getattr(args, 'interval', 300)
        print(f"\n[ğŸš€ START] è¿›å…¥é«˜é¢‘æ‰«ææ¨¡å¼ | é—´éš”: {interval}s")
        try:
            while True:
                print(f"\n{'='*60}")
                print(f"è¿­ä»£ #{iteration} | å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
                print(f"{'='*60}")

                perform_scan_task()

                print(f"\n[WAIT] æ‰«æå®Œæˆï¼Œç­‰å¾… {interval} ç§’è¿›å…¥ä¸‹ä¸€æ¬¡è¿­ä»£...")
                time.sleep(interval)
                iteration += 1
        except KeyboardInterrupt:
            print("\n[STOP] ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºé«˜é¢‘æ¨¡å¼")
            return 0
        finally:
            scanner.close()


if __name__ == "__main__":
    sys.exit(0 if main() >= 0 else 1)